var relearn_searchindex = [
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Công nghệ dạy về sự đồng cảm? Cách mà mpathic sử dụng AI để giúp chúng ta lắng nghe nhau Bonnie McClure và Chalaire Miller | 30/4/2024 | Startup, Startup Spotlight\nỞ cấp độ cơ bản của con người, chúng ta muốn lắng nghe. Chúng ta muốn kết nối, và muốn hiểu người khác. Thật không may, chúng ta thường đối mặt với nhiều thứ canh trạnh với sự chú ý của mình, cái mà khiến chúng ta trờ thành người lắng nghe kém\nLắng nghe tích cực là một hành vi được hình thành qua việc học hỏi và không dễ để trở nên thành thục. Nhưng nếu trí thông minh nhân tạo (AI) có thể giúp chúng ta có thể thực sự lắng nghe và hiểu người khác thì sao? Liệu rằng công nghệ có thể tận dụng những kinh nghiệm sống mà ta tích lũy được trong cuộc sống và giúp chúng ta trở nên nhân văn hơn với nhau?\nĐây chính là những câu hỏi mà Tiến sĩ Grin Lord – nhà tâm lý học lâm sàng, đồng thời là người sáng lập công ty phân tích hội thoại mpathic – đã dành 15 năm qua để nghiên cứu và theo đuổi. Trong suốt quá trình nghiên cứu, Grinn và đội của mình tại mpathic đã xác định các từ, cụm từ và hành vi giao tiếp từ đó mô hình hóa chúng bằng AI\n“Chúng tôi xem xét những gì thúc đẩy niềm tin, những gì thúc đẩy sự gắn kết và cách chúng tác động đến kết quả” - Tiến sĩ Danielle Schlosser, Giám đốc Đổi mới của mpathic chia sẽ\nTrong quá trình theo đuổi phương pháp tiếp cận dựa trên công nghệ để mở khóa sự đồng cảm, mpathic đã phát triển một vài thứ độc nhất: một giải pháp mà không chỉ có việc phân tích và đánh giá chất lượng các cuộc trò chuyện mà cũng cung cấp những đề xuất cho việc nâng cao sự đồng cảm, lòng tin và sự gắn kết theo thời gian thực.\n“Điểm khác biệt của chúng tôi là hướng đến yếu tố hành vi và có thể hành động được ngay.” - Grin nói. “Chúng tôi muốn huấn luyện mọi người cách để cải thiện”\nTận dụng những phản hồi từ nhóm các chuyên gia từ nhiều lĩnh vực được đào tạo chuyên sâu về sự thấu cảm, API của mpathic có thể nhanh chóng dán nhãn những tình huống hiểu lầm trong các cuộc trò chuyện và ngay lập tức để nghị phản hồi và đề xuất làm sao để có thể lắng nghe và phản hồi một cách đồng cảm hơn.\nKết quả thật đáng kinh ngạc. Khi mà triển khai trong các thử nghiệm lâm sàng, nhà cung cấp dịch vụ chăm sóc sức khỏe sử dụng API của mpathic có khả năng nắm bắt rủi ro của người tham gia và cung cấp phản hồi quan trọng cao hơn 7 lần. Tương tự như vậy, trong các trường hợp sử dụng phần mềm bán hàng và nhân sự dưới dạng dịch vụ (SaaS), các doanh nghiệp sử dụng sản phẩm mpathic đã chứng kiến ​​sự tương tác, mức độ hài lòng và nhiều kết quả khác của khách hàng cao hơn.\nTiếp tục thử nghiệm và hoàn thiện giáo dục thấu cảm Xem xét bối cảnh và sắc thái, mpathic định nghĩa sự đồng cảm là “sự thấu hiểu chính xác”. Nhưng để có thể thiết kế một phương thức thành công cho việc giáo dục thấu cảm hóa ra lại khó nắm bắt hơn việc định nghĩa nó.\nKhoảng trước năm 2000, Grin bắt đầu hành trình của mình trong lĩnh vực nghiên cứu bằng việc làm việc với những tài xế liên quan đến các vụ tai nạn do lái xe khi say rượu. Thí nghiệm bao gồm những can thiệp ngắn, bao gồm 15 phút lắn nghe sự thấu cảm, đưa ra sự chấp thuận và thấu hiểu trải nghiệm của người lái xe.Sự can thiệp thấu cảm nhỏ này dẫn tới việc giảm thiểu được hành vi uống rượu trong hơn 3 năm sau đó và đồng thời làm giảm 46% số ca tái nhập viện.\nSau đó, Grin đã huấn luyện các tiến sĩ y học cách để lắng nghe với sự đồng cảm, dạy các hành vi như là lắng nghe phản ánh, đặt câu hỏi mở thay vì câu hỏi đóng, và sử dụng lời khẳng định.\nKhi nhận ra rằng một khóa huấn luyện kéo dài hai ngày là chưa đủ để thay đổi những hành vi và phong cách giao tiếp ăn sâu từ lâu, Grin đã điều chỉnh lại cách tiếp cận của mình. Cô học hỏi những kỹ thuật này từ một nghiên cứu huấn luyện qua điện thoại trên phạm vi toàn quốc, trong đó các bác sĩ tự ghi âm lại quá trình họ đưa ra phản hồi. Sau đó, một nhà tâm lý học sẽ lắng nghe và đưa ra gợi ý cải thiện dựa trên hiệu suất. Quá trình này thường kéo dài nhiều tuần, vì vậy vào năm 2008, Grin đã nắm bắt cơ hội áp dụng machine learning (ML) để đẩy nhanh tiến trình.\nTại Đại học Washington, Grin tham gia nhóm xây dựng những quy trình xử lý tín hiệu giọng nói đầu tiên phục vụ việc phản hồi dựa trên hiệu suất trong môi trường y tế. “Với sức mạnh tính toán khi đó, cần khoảng 6 tiếng để xử lý một cuộc gọi dài 30 phút,” cô chia sẻ. “Nhưng việc có thể nhận được phản hồi ngay trong ngày đã được coi là một cuộc cách mạng.”\nNgày nay, với năng lực tính toán vượt trội, tầm nhìn ban đầu về việc cung cấp phản hồi theo thời gian thực cho nhân viên y tế đã trở thành hiện thực. Qua nhiều năm, Grin đã xây dựng một đội ngũ gồm các chuyên gia đầu ngành và nhà nghiên cứu — từ những người tham gia nghiên cứu gốc tại Đại học Washington, cũng như các chuyên gia AI ở Đại học Carnegie Mellon, cho đến các chuyên gia công nghệ đến từ những tập đoàn lớn.\nÝ tưởng về mpathic ra đời khi Grin và nhóm của mình nhận ra giá trị thương mại của việc lắng nghe đầy thấu cảm: “Liệu chúng ta có thể tạo ra một API có khả năng ngay lập tức biến mọi cuộc giao tiếp trở nên giàu tính thấu cảm, bất kể bối cảnh sử dụng là gì?”\nĐội ngũ đã xây dựng những mô hình đầu tiên của mpathic từ dữ liệu thu thập được trong trò chơi huấn luyện về sự thấu cảm mang tên Empathy Rocks. Trong trò chơi này, các nhà trị liệu — bao gồm cả thành viên của Đường dây Khủng hoảng Bang Idaho và Dịch vụ Y tế Người Mỹ bản địa tại California — sẽ phản hồi một cách đầy thấu cảm với người dùng ẩn danh (dữ liệu từ các diễn đàn công cộng), đồng thời chấm điểm lẫn nhau về mức độ thấu cảm trong câu trả lời. Họ cũng nhận được tín chỉ đào tạo liên tục khi tham gia trò chơi. “Chúng tôi đã có một tập hợp rất đa dạng những người cùng chung tay xây dựng các mô hình này thông qua thông qua việc huy động cộng đồng” Grin giải thích.\nMở rộng đào tạo và công cụ thấu cảm trên khắp các ngành Khi mpathic tiếp tục phát triển và mở rộng năng lực, startup này hiện đã có hơn 200 mô hình khác nhau về hành vi giao tiếp, kèm theo các mẹo và gợi ý, bao gồm cách cải thiện sự hợp tác và chia sẻ quyền lực, cũng như lắng nghe chính xác hơn thông qua phản hồi và đặt câu hỏi mở. Họ cũng đo lường những chỉ số tiềm ẩn hơn về sự đồng điệu của con người, như sự đồng bộ trong phong cách ngôn ngữ, mà theo nghiên cứu của Grin đã được chứng minh là có tính dự báo cao hơn đối với việc đánh giá khách quan về sự thấu cảm so với các kỹ năng khác. “Mục tiêu không phải thay thế trải nghiệm con người,” Tiến sĩ Amber Jolley-Paige, Phó Chủ tịch Sản phẩm Lâm sàng, chia sẻ, “mà là để tăng cường nó.”\nVới cách tiếp cận linh hoạt và phù hợp theo nhu cầu, mpathic sử dụng phân tích và các chỉ số để hỗ trợ mục tiêu và KPI cụ thể của khách hàng, bất kể ngành nào. Hiện họ cung cấp một bộ sản phẩm AI gồm: mpathic API cốt lõi, mConsult, và mTrial. mpathic API cốt lõi tích hợp vào phần mềm khác, phân tích giao tiếp và đưa ra gợi ý hành động. Ví dụ, khi mpathic dùng API để phân tích phỏng vấn tuyển dụng cho nhiều công ty, họ phát hiện rằng những ứng viên nhận được phản hồi thấu cảm có tỷ lệ chấp nhận công việc cao hơn 8%. mConsult cung cấp khuyến nghị và huấn luyện ngay lập tức bằng cách xem xét bản ghi âm hoặc ghi hình. Và mTrial tối ưu hóa các thử nghiệm lâm sàng bằng cách nâng cao chất lượng dữ liệu và đảm bảo tính nhất quán trong chăm sóc, đồng thời chủ động giảm rủi ro và giảm bớt khối lượng công việc cho các chuyên gia y tế.\nHình dung về tương lai công bằng y tế Hành trình của mpathic chưa có dấu hiệu chậm lại. Để đạt được mục tiêu cải thiện giao tiếp giữa con người, nhóm nghiên cứu đang mở rộng API của mình để giải quyết các hành vi đa dạng về văn hóa và hỗ trợ các nhà cung cấp dịch vụ huấn luyện trong việc thích ứng văn hóa.\nVăn hóa có thể ảnh hưởng đến cách con người giao tiếp theo nhiều cách khác nhau. Ví dụ, nó có thể tác động đến phong cách giao tiếp, cách con người truyền tải thông tin, và thái độ đối với xung đột. “Với mpathic, chúng ta có khả năng chưa từng có để tạo ra nhiều sự thấu cảm hơn trong các tương tác chăm sóc sức khỏe, và hình dung về một tương lai nơi AI có thể được tận dụng để cải thiện công bằng sức khỏe,” chia sẻ của Tiến sĩ Alison Cerezo, Trưởng bộ phận Nghiên cứu và Công bằng sức khỏe.\nCông ty khởi nghiệp này đã xây dựng tập dữ liệu huấn luyện từ một nhóm đa dạng về giới tính, văn hóa và nền tảng nhằm giảm thiểu thiên lệch trong AI. “Nhiều vấn đề bạn thấy với thiên lệch AI bắt nguồn từ việc mô hình được xây dựng từ dữ liệu chỉ thu thập ở một hoặc hai bối cảnh, và không hiểu được trải nghiệm sống thực tế của những người mà mô hình đó sẽ ảnh hưởng,” Grin giải thích. mpathic đảm bảo rằng họ luôn thường xuyên xây dựng, tinh chỉnh và triển khai các mô hình của mình với sự chú ý và phù hợp với khuôn khổ AI có đạo đức.\nTiếp tục phát triển, đội ngũ tại mpathic dự định sẽ tiếp tục xây dựng các công cụ AI có khả năng nhận diện những quan điểm tinh tế và đa dạng hiện tại trong mọi tương tác giữa con người. “Công nghệ này không có giới hạn trong việc đào tạo bất kỳ ai biết lắng nghe với sự thấu cảm,” Grin cho biết.\nPhát triển lớn mạnh cùng AWS Để mở rộng nền tảng, mpathic cần một hạ tầng mạnh mẽ. AWS đã mang đến cho mpathic một nền tảng đáng tin cậy, ổn định để phát triển và đổi mới một cách an toàn. “Chúng tôi xây dựng trên AWS để giúp chúng tôi mở rộng hiệu quả và đáp ứng nhu cầu khách hàng một cách nhanh chóng và liền mạch” Grin cho biết. “Chúng tôi chỉ là một công ty khởi nghiệp tương đối nhỏ nhưng lại phục vụ khách hàng trên toàn cầu. Việc có thể nói với khách hàng rằng chúng tôi có thể lưu trữ dữ liệu ở bất cứ đâu trên thế giới là một điều tuyệt vời — và điều đó sẽ không thể thực hiện được nếu không có AWS.” mpathic sử dụng AWS cho tất cả các thành phần nền tảng cốt lõi, bao gồm tính toán, lưu trữ và hạ tầng mạng, đảm bảo việc truyền tải và lưu trữ dữ liệu xuyên biên giới một cách an toàn.\nNgoài công nghệ, sự hợp tác giữa mpathic và AWS được xây dựng trên cam kết chung trong việc giúp mpathic đạt được mục tiêu của mình. “Mức độ quan tâm và hỗ trợ thật sự ấn tượng, đặc biệt là khi đến từ một tổ chức lớn như vậy,” Danielle nói. “Nó không chỉ là về công nghệ, mà còn là về sự kết nối.”\n“AWS cũng đã làm rất nhiều để tôn vinh các nhà sáng lập nữ, điều mà tôi nghĩ là rất tuyệt vời,” Megan Greenlaw, Phó Chủ tịch Khoa học Đời sống và AI Tâm lý học, chia sẻ thêm. “Đối với tôi, điều đó thể hiện một sự thay đổi đang diễn ra trong lĩnh vực đầu tư mạo hiểm. Việc một công ty có thể gọi vốn hơn 10 triệu USD và 90% trong số đó đến từ các nhà đầu tư nữ thật sự là một điều xuất sắc,” Grin nói.",
    "description": "Công nghệ dạy về sự đồng cảm? Cách mà mpathic sử dụng AI để giúp chúng ta lắng nghe nhau Bonnie McClure và Chalaire Miller | 30/4/2024 | Startup, Startup Spotlight\nỞ cấp độ cơ bản của con người, chúng ta muốn lắng nghe. Chúng ta muốn kết nối, và muốn hiểu người khác. Thật không may, chúng ta thường đối mặt với nhiều thứ canh trạnh với sự chú ý của mình, cái mà khiến chúng ta trờ thành người lắng nghe kém",
    "tags": [],
    "title": "Blog 1",
    "uri": "/vi/3-blogstranslated/3.1-blog1/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các sự kiện đã tham gia",
    "content": "Bài thu hoạch “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” Mục Đích Của Sự Kiện Quy tụ các doanh nghiệp, nhà phát triển và lãnh đạo để cùng nhau khai thác những đổi mới trong lĩnh vực điện toán đám mây và AI. Giúp Việt Nam đẩy mạnh chuyển đổi số, khám phá những công nghệ Gen AI, cloud và những giải pháp kỹ thuật số mới cho tương lai Khám phá các giải pháp tiên tiến từ các chuyên gia và đối tác của Amazon Web Services (AWS) Là cơ hội để kết nối với công động công nghệ Danh sách các diễn giả Eric Yeo : Country General Manager, Vietnam, Cambodia, Laos \u0026 Myanmar, AWS Dr. Jens Lottner: CEO, Techcombank Ms. Trang Phung: CEO \u0026 Co-Founder, U2U Network Jaime Valles: Vice President, General Manager Asia Pacific and Japan, AWS Jeff Johnson: Managing Director, ASEAN, AWS Vu Van: Co-founder \u0026 CEO, ELSA Corp Nguyen Hoa Binh: Chairman, Nexttech Group' Dieter Botha: CEO, TymeX Hung Nguyen Gia: Head of Solutions Architect, AWS Son Do: Technical Account Manager, AWS Nguyen Van Hai: Director of Software Engineering, Techcombank Phuc Nguyen: Solutions Architect, AWS Alex Tran: AI Director, OCB Nguyen Minh Ngan: AI Specialist, OCB Nguyen Manh Tuyen: Head of Data Application, LPBank Securities Vinh Nguyen: Co-Founder \u0026 CTO, Ninety Eight Hung Hoang: Customer Solutions Manager, AWS Taiki Dang: Solutions Architect, AWS Nội Dung Nổi Bật Tận dụng AWS Q để cải thiện và nâng cao năng suất cho lập trình viên Cải thiện chất lượng code Đẩy nhanh việc triển khai các giải pháp Cung cấp trợ lý lập trình thông minh Duy trì sự tuân thủ nghiêm ngặt, quyền riêng tư và bảo mật dữ liệu Khai phá tiềm năng AI của Việt Nam Tỷ lệ tăng trưởng áp dụng AI đạt 39% 55% doanh nghiệp Việt Nam cho rằng kỹ năng số hạn chế là rào cản chính đối với việc áp dụng và mở rộng AI. Di chuyển, hiện đại hóa và xây dựng trên AWS Tìm hiểu các chiến lược di chuyển và hiện đại hóa quy mô lớn trên AWS thông qua các nghiên cứu điển hình thực tế từ Techcombank. Nâng cao kiến thức về việc hiện đại hóa ứng dụng bằng các công cụ được hỗ trợ bởi Generative AI, với những hiểu biết thực tế từ VPBank Nhận được những chia sẻ sâu sắc từ các chuyên gia hàng đầu ngành thông qua các buổi thảo luận nhóm về hiện đại hóa ứng dụng Tìm hiểu về hiện đại hóa đám mây dựa trên trí tuệ nhân tạo đặc biệt dành cho môi trường VMware Hiểu rõ các thực hành tốt nhất về bảo mật AWS từ môi trường phát triển đến môi trường sản xuất Kết nối và học hỏi trực tiếp từ các Kiến trúc sư Giải pháp AWS và các chuyên gia trong ngành Những gì học được Tại sao hiện đại hóa lại quan trọng ? Những thách thức từ hệ thống cũ: làm chậm quá trình đổi mới và làm tăng chi phí Lợi ích của hiện đại hóa: tạo điều kiện cho sự linh hoạt, cung cấp thông tin chuyên sâu và thúc đẩy đổi mới lấy khách hàng làm trung tâm. Tác động đến doanh nghiệp: hiệu quả, khả năng mở rộng, khả năng phục hồi, tính canh tranh và bền vững Hành trình Hiện đại hóa Đánh giá (Assess): Kiểm kê môi trường hiện tại, xác định các điểm yếu. Khởi động (Mobilize): Thiết lập Trung tâm Năng lực Chuyên môn (CCoE), xây dựng các nguyên tắc hướng dẫn và phát triển năng lực sử dụng đám mây. Di chuyển \u0026 Hiện đại hóa (Migrate \u0026 Modernize): Ưu tiên các công việc có tác động cao để di chuyển và hiện đại hóa. Tái tạo (Reinvent): Ứng dụng trí tuệ nhân tạo (AI), tự động hóa, sản phẩm dữ liệu và các mô hình kinh doanh mới. AWS Transform (Dịch vụ AI có khả năng tự động hành động (agentic AI) đầu tiên dành cho việc di chuyển và hiện đại hóa quy mô lớn) Đánh giá (Assessment): Xây dựng lập luận kinh doanh (business case) để di chuyển sang AWS. VMware: Công cụ hỗ trợ giúp di chuyển từ môi trường VMware sang Amazon EC2. Mainframe: Công cụ hỗ trợ (agent) để hiện đại hóa các ứng dụng IBM z/OS (hệ thống máy chủ lớn). .NET: Công cụ hỗ trợ (agent) để hiện đại hóa các ứng dụng .NET dựa trên Windows sang nền tảng Linux. Các thách thức về bảo mật đám mây Rào cản đổi mới (Innovation roadblocks): Cách tiếp cận bảo mật truyền thống có thể khiến đội ngũ bảo mật bị coi là rào cản cho sự đổi mới. Thiếu chuyên môn \u0026 nguồn lực (Expertise \u0026 resource shortages): Các nhóm bảo mật hiện tại đang hoạt động ở mức năng lực tối đa và dành phần lớn thời gian cho các nhiệm vụ lặp lại, giá trị thấp. Quy mô và độ phức tạp (Scale and complexity): Việc quản lý bảo mật ở quy mô lớn trong môi trường đám mây đa dạng và phức tạp là một thách thức lớn. Bối cảnh mối đe dọa đang thay đổi (Evolving threat landscapes): Các chiến thuật tấn công và công nghệ mới liên tục xuất hiện, tạo ra một môi trường rủi ro luôn biến động. Yêu cầu về bảo vệ dữ liệu \u0026 quyền riêng tư (Data protection \u0026 privacy demands): Để duy trì niềm tin của khách hàng, các tổ chức phải đáp ứng các yêu cầu nghiêm ngặt về bảo vệ dữ liệu và quyền riêng tư theo quy định ngành (ví dụ: GDPR, PCI-DSS…). Threat Intelligence là nền tảng giúp các dịch vụ AWS phản ứng nhanh chóng, chủ động trước các mối đe dọa mới. AWS Shield Amazon GuardDuty Amazon S3 AWS WAF (Web Application Firewall) AWS Network Firewall Amazon Route 53 Resolver DNS Firewall Amazon VPC (Virtual Private Cloud) Trải nghiệm trong event Tham gia workshop “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng, công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Migration, Modernization và Cloud Security vào các project lớn. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Chiến lược hiện đại hóa cần phased approach và đo lường, đánh giá chính xác tình trạng hiện tại, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại.",
    "description": "Bài thu hoạch “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” Mục Đích Của Sự Kiện Quy tụ các doanh nghiệp, nhà phát triển và lãnh đạo để cùng nhau khai thác những đổi mới trong lĩnh vực điện toán đám mây và AI. Giúp Việt Nam đẩy mạnh chuyển đổi số, khám phá những công nghệ Gen AI, cloud và những giải pháp kỹ thuật số mới cho tương lai Khám phá các giải pháp tiên tiến từ các chuyên gia và đối tác của Amazon Web Services (AWS) Là cơ hội để kết nối với công động công nghệ Danh sách các diễn giả Eric Yeo : Country General Manager, Vietnam, Cambodia, Laos \u0026 Myanmar, AWS Dr. Jens Lottner: CEO, Techcombank Ms. Trang Phung: CEO \u0026 Co-Founder, U2U Network Jaime Valles: Vice President, General Manager Asia Pacific and Japan, AWS Jeff Johnson: Managing Director, ASEAN, AWS Vu Van: Co-founder \u0026 CEO, ELSA Corp Nguyen Hoa Binh: Chairman, Nexttech Group' Dieter Botha: CEO, TymeX Hung Nguyen Gia: Head of Solutions Architect, AWS Son Do: Technical Account Manager, AWS Nguyen Van Hai: Director of Software Engineering, Techcombank Phuc Nguyen: Solutions Architect, AWS Alex Tran: AI Director, OCB Nguyen Minh Ngan: AI Specialist, OCB Nguyen Manh Tuyen: Head of Data Application, LPBank Securities Vinh Nguyen: Co-Founder \u0026 CTO, Ninety Eight Hung Hoang: Customer Solutions Manager, AWS Taiki Dang: Solutions Architect, AWS Nội Dung Nổi Bật Tận dụng AWS Q để cải thiện và nâng cao năng suất cho lập trình viên Cải thiện chất lượng code Đẩy nhanh việc triển khai các giải pháp Cung cấp trợ lý lập trình thông minh Duy trì sự tuân thủ nghiêm ngặt, quyền riêng tư và bảo mật dữ liệu Khai phá tiềm năng AI của Việt Nam Tỷ lệ tăng trưởng áp dụng AI đạt 39% 55% doanh nghiệp Việt Nam cho rằng kỹ năng số hạn chế là rào cản chính đối với việc áp dụng và mở rộng AI. Di chuyển, hiện đại hóa và xây dựng trên AWS Tìm hiểu các chiến lược di chuyển và hiện đại hóa quy mô lớn trên AWS thông qua các nghiên cứu điển hình thực tế từ Techcombank. Nâng cao kiến thức về việc hiện đại hóa ứng dụng bằng các công cụ được hỗ trợ bởi Generative AI, với những hiểu biết thực tế từ VPBank Nhận được những chia sẻ sâu sắc từ các chuyên gia hàng đầu ngành thông qua các buổi thảo luận nhóm về hiện đại hóa ứng dụng Tìm hiểu về hiện đại hóa đám mây dựa trên trí tuệ nhân tạo đặc biệt dành cho môi trường VMware Hiểu rõ các thực hành tốt nhất về bảo mật AWS từ môi trường phát triển đến môi trường sản xuất Kết nối và học hỏi trực tiếp từ các Kiến trúc sư Giải pháp AWS và các chuyên gia trong ngành Những gì học được Tại sao hiện đại hóa lại quan trọng ? Những thách thức từ hệ thống cũ: làm chậm quá trình đổi mới và làm tăng chi phí Lợi ích của hiện đại hóa: tạo điều kiện cho sự linh hoạt, cung cấp thông tin chuyên sâu và thúc đẩy đổi mới lấy khách hàng làm trung tâm. Tác động đến doanh nghiệp: hiệu quả, khả năng mở rộng, khả năng phục hồi, tính canh tranh và bền vững Hành trình Hiện đại hóa Đánh giá (Assess): Kiểm kê môi trường hiện tại, xác định các điểm yếu. Khởi động (Mobilize): Thiết lập Trung tâm Năng lực Chuyên môn (CCoE), xây dựng các nguyên tắc hướng dẫn và phát triển năng lực sử dụng đám mây. Di chuyển \u0026 Hiện đại hóa (Migrate \u0026 Modernize): Ưu tiên các công việc có tác động cao để di chuyển và hiện đại hóa. Tái tạo (Reinvent): Ứng dụng trí tuệ nhân tạo (AI), tự động hóa, sản phẩm dữ liệu và các mô hình kinh doanh mới. AWS Transform (Dịch vụ AI có khả năng tự động hành động (agentic AI) đầu tiên dành cho việc di chuyển và hiện đại hóa quy mô lớn) Đánh giá (Assessment): Xây dựng lập luận kinh doanh (business case) để di chuyển sang AWS. VMware: Công cụ hỗ trợ giúp di chuyển từ môi trường VMware sang Amazon EC2. Mainframe: Công cụ hỗ trợ (agent) để hiện đại hóa các ứng dụng IBM z/OS (hệ thống máy chủ lớn). .NET: Công cụ hỗ trợ (agent) để hiện đại hóa các ứng dụng .NET dựa trên Windows sang nền tảng Linux. Các thách thức về bảo mật đám mây Rào cản đổi mới (Innovation roadblocks): Cách tiếp cận bảo mật truyền thống có thể khiến đội ngũ bảo mật bị coi là rào cản cho sự đổi mới. Thiếu chuyên môn \u0026 nguồn lực (Expertise \u0026 resource shortages): Các nhóm bảo mật hiện tại đang hoạt động ở mức năng lực tối đa và dành phần lớn thời gian cho các nhiệm vụ lặp lại, giá trị thấp. Quy mô và độ phức tạp (Scale and complexity): Việc quản lý bảo mật ở quy mô lớn trong môi trường đám mây đa dạng và phức tạp là một thách thức lớn. Bối cảnh mối đe dọa đang thay đổi (Evolving threat landscapes): Các chiến thuật tấn công và công nghệ mới liên tục xuất hiện, tạo ra một môi trường rủi ro luôn biến động. Yêu cầu về bảo vệ dữ liệu \u0026 quyền riêng tư (Data protection \u0026 privacy demands): Để duy trì niềm tin của khách hàng, các tổ chức phải đáp ứng các yêu cầu nghiêm ngặt về bảo vệ dữ liệu và quyền riêng tư theo quy định ngành (ví dụ: GDPR, PCI-DSS…). Threat Intelligence là nền tảng giúp các dịch vụ AWS phản ứng nhanh chóng, chủ động trước các mối đe dọa mới. AWS Shield Amazon GuardDuty Amazon S3 AWS WAF (Web Application Firewall) AWS Network Firewall Amazon Route 53 Resolver DNS Firewall Amazon VPC (Virtual Private Cloud) Trải nghiệm trong event Tham gia workshop “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng, công cụ hiện đại. Một số trải nghiệm nổi bật:",
    "tags": [],
    "title": "Sự kiện 1",
    "uri": "/vi/4-eventparticipated/4.1-event1/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console management. Thảo luận về chủ đề và công nghệ cho project đầu tiên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 5 - Viết log và cấu hình cho bài workshop 11/09/2025 11/9/2025 6 - Xem các video bài giảng và nghiên cứu thêm các thuật ngữ xuất hiện trong module 2 12/09/2025 12/9/2025 3 - Thực hành: + lab01: Tạo account đầu tiên, sử dụng IAM, tạo MFA + lab07: Tạo các budget 9/9/2025 9/9/2025 https://000001.awsstudygroup.com/vi/ https://000007.awsstudygroup.com/vi/ 4 - Tìm hiểu cách làm workshop cá nhân bằng hugo.io - Dịch bài blogs của AWS 10/9/2025 10/9/2025 https://mcshelby.github.io/hugo-theme-relearn/index.html https://aws.amazon.com/blogs/startups/technology-that-teaches-empathy-how-mpathic-uses-ai-to-help-us-listen-to-each-other/ https://gohugo.io/getting-started/quick-start/ 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập - Xem video bài giảng về module 1 - Tìm hiểu về các thuật ngữ: AWS Regions, AWS Availability Zones, AWS Points of Presence (Edge Locations) 8/9/2025 8/9/2025 https://policies.fcjuni.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và có hiểu biết cơ bản về cơ sở hạ tầng toàn cầu của AWS:\nCompute Storage IAM … Thực hành khởi tạo tài khoản aws:\nTạo một tài khoản mới trong aws Cài đặt MFA cho tài khoản mới Tạo IAM User là Admin để sử dụng trong các tác vụ hằng ngày Tìm hiểu về AWS Support Làm quen với AWS Management Console và biết cách tìm, truy cập và sử dụng các dịch vụ từ giao diện web.\nQuản lý ngân sách bằng cách tạo ngân sách và thiết lập cảnh báo.\nCấu hình dự án hugo để viết bài workshop.",
    "description": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console management. Thảo luận về chủ đề và công nghệ cho project đầu tiên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 5 - Viết log và cấu hình cho bài workshop 11/09/2025 11/9/2025 6 - Xem các video bài giảng và nghiên cứu thêm các thuật ngữ xuất hiện trong module 2 12/09/2025 12/9/2025 3 - Thực hành: + lab01: Tạo account đầu tiên, sử dụng IAM, tạo MFA + lab07: Tạo các budget 9/9/2025 9/9/2025 https://000001.awsstudygroup.com/vi/ https://000007.awsstudygroup.com/vi/ 4 - Tìm hiểu cách làm workshop cá nhân bằng hugo.io - Dịch bài blogs của AWS 10/9/2025 10/9/2025 https://mcshelby.github.io/hugo-theme-relearn/index.html https://aws.amazon.com/blogs/startups/technology-that-teaches-empathy-how-mpathic-uses-ai-to-help-us-listen-to-each-other/ https://gohugo.io/getting-started/quick-start/ 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập - Xem video bài giảng về module 1 - Tìm hiểu về các thuật ngữ: AWS Regions, AWS Availability Zones, AWS Points of Presence (Edge Locations) 8/9/2025 8/9/2025 https://policies.fcjuni.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và có hiểu biết cơ bản về cơ sở hạ tầng toàn cầu của AWS:",
    "tags": [],
    "title": "Tuần 1",
    "uri": "/vi/1-worklog/1.1-week1/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập",
    "content": "Thông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Xây dựng VPC và Hyrid DNS với Route53\nTuần 3: Tìm hiểu về Dịch vụ Compute VM trên AWS\nTuần 4: Tìm hiểu về Dịch vụ lưu trữ Amazon S3\nTuần 5: Tìm hiểu về Dịch vụ bảo mật trên AWS\nTuần 6: Học về dịch vụ cơ sở dữ liệu trên cloud của AWS\nTuần 7: Tập triển khai khai ứng dụng lên aws với docker",
    "description": "Thông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Xây dựng VPC và Hyrid DNS với Route53\nTuần 3: Tìm hiểu về Dịch vụ Compute VM trên AWS\nTuần 4: Tìm hiểu về Dịch vụ lưu trữ Amazon S3",
    "tags": [],
    "title": "Worklog",
    "uri": "/vi/1-worklog/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Tiết kiệm nhờ công nghệ: Những cách sáng tạo để cắt giảm chi phí cho doanh nghiệp nhỏ của bạn Henrique Trevisan, Jonathan Woods, and Vince Anderson | 23/4/2024 | in Best Practices, Permalink\nViệc vận hành một doanh nghiệp nhỏ có nghĩa là tận dụng tối đa từng đô la trong khi vẫn duy trì dịch vụ chất lượng cao. Khi doanh nghiệp và nền tảng đám mây của bạn sử dụng mở rộng, bạn phải tìm cách để quản lý nguồn lực công nghệ một cách hiệu quả để bảo vệ lợi nhuận của bạn. Trong môi trường kinh tế thách thức ngày nay, tối ưu chi phí đã trở thành là ưu tiên hàng đầu của chủ doanh nghiệp những người muốn cắt giảm chi phí mà không cần hy sinh hiệu năng, bảo mật và trải nghiệm người dùng.\nBài đăng trên blog này khám phá các chiến lược thực tế - trong ngắn hạn, trung hạn và dài hạn - cho doanh nghiệp nhỏ có thể tối ưu hóa chi phí điện toán đám mây của họ trong khi tiếp tục tận dụng các khả năng mạnh mẽ của hạ tầng điện toán đám mây như Amazon Web Services (AWS) cung cấp. Cho dù bạn mới bắt đầu hành trình điện toán đám mây hay muốn cải thiện thiết lập hiện tại, những thông tin chi tiết này sẽ cung cấp hướng dẫn có giá trị về cách đầu tư công nghệ thông minh đồng thời kiểm soát chi phí.\nCác bước nhanh chóng để tiết kiệm chi phí ngay lập tức 1. Hiện đại hóa chiến lược lưu trữ của bạn Nhiều doanh nghiệp nhỏ thường trả rất nhiều tiền cho việc lưu trữ dữ liệu bởi vì họ không tối ưu hóa cấu hình của chính mình. Quản lý chiến lược lưu trữ thông minh bao gồm 3 chiến lược chính:\nTriển khai phân tầng (tiering): chuyển dữ liệu ít được truy cập sang các tùy chọn lưu trữ chi phí thấp hơn, chỉ giữ dữ liệu thường xuyên sử dụng ở bộ nhớ cao cấp. Phân bổ dung lượng hợp lý: nhiều doanh nghiệp trả tiền cho dung lượng vượt xa nhu cầu thực tế. Cấu hình hiệu suất lưu trữ: điều chỉnh theo nhu cầu thực tế thay vì giữ nguyên thiết lập mặc định. Cách tiếp cận cân bằng này có thể làm giảm thiểu chi phí lưu trữ trong khi vẫn duy trì hoặc thậm chí cải thiện hiệu năng. Cách tối ưu hóa đó yêu câu một nổ lực kỹ thuật tối thiểu nhưng mang lại khoản tiết kiệm tức thời và liên tục cho hóa đơn hàng tháng của bạn\n2. Loại bỏ chi phí chứng chỉ không cần thiết Tại sao phải trả cho bên thứ ba các chứng chỉ về Secure Sockets Layer/Transport Layer Security(SSL/TLS) trong khi bạn có thể sử dụng chúng miễn phí? Nhiều doanh nghiệp tiếp tục trả phí hàng tháng để nhà cung cấp chứng chỉ theo thói quen, họ thường dành 100$ mỗi tháng cho một vài thứ hiện tại không còn tốn phí. Bằng cách đưa chứng chỉ bảo vệ website của bạn tới [Amazon Route 53] thông qua AWS Certificate Manager (ACM), bạn có thể loại bỏ chỉ phí định kỳ này đồng thời nhận được lợi từ việc tự động gia hạn các chứng chỉ. Doanh nghiệp nhỏ khi thực hiện thay đổi này loại bỏ gánh nặng quản trị trong việc theo dõi ngày hết hạn và gia hạn chứng chỉ thử công. Đây là một thay đổi đơn giản nhưng có thể làm giảm cả chi phí và rủi ro bảo mật với nổ lực triển khai tối thiểu.\n3. Tối ưu hóa việc lưu trữ log data Một số doanh nghiệp vô tình lưu trữ log data lâu hơn mức cần thiết, khiến chi phí lưu trữ trên cloud hàng tháng tăng lên. Hầu hết các công cụ quản lý log đều cho phép triển khai chính sách lưu trữ tự động phù hợp với nhu cầu kinh doanh thực tế. Bằng cách cấu hình thời gian lưu trữ log hợp lý — thay vì giữ nguyên cài đặt mặc định không giới hạn — doanh nghiệp có thể giảm đáng kể dung lượng lưu trữ trong khi vẫn đảm bảo tuân thủ quy định. Trên AWS, Amazon CloudWatch khiến cho quá trình này trở nên đơn giản với các thiết lập dễ dùng cho phép lưu trữ log bảo mật quan trọng trong 90 ngày trong khi chỉ giữ log vận hành trong 30 ngày. Cách tiếp cận tùy chỉnh này thường giúp giảm chi phí lưu trữ log so với việc giữ vô thời hạn, đồng thời tự động hóa giúp đội ngũ không phải xóa log cũ thủ công. Với hầu hết các chuẩn tuân thủ, 30–90 ngày log là đủ, thay vì lưu trữ nhiều năm dữ liệu hiếm khi được truy cập.\nChiến lược tối ưu chi phí trung hạn 1. Hợp nhất tài nguyên mạng trong khi vẫn duy trì sự bảo mật Khi doanh nghiệp của bạn phát triển để phục vụ nhiều khách hàng hoặc phòng ban, việc tạo ra các môi trường đám mây hoàn toàn riêng biệt cho từng phòng ban có vẻ là cách tiếp cận an toàn nhất. Việc này ban đầu là có hiệu quả, nhưng nó sẽ nhân chi phí của bạn lên 1 cách không cần thiết khi bạn mở rộng quy mô. Những doanh nghiệp nhỏ đang tìm cacsg để chia sẽ cơ sở hạ tầng mạng cốt lõi trong khi sử dụng ranh giới ảo bằng dịch vụ như Amazon Virtual Private Cloud (Amazon VPC) để giữ cho dữ liệu người dùng được tách biệt an toàn. Cách tiếp cận cân bằng này có thể giúp bạn đạt được các mục tiêu về bảo mật và tuân thủ đồng thời giảm bớt các thành phần mạng dư thừa. Những công ty áp dụng chiến lược hợp nhất mạng này có thể cắt giảm chi phí hạ tầng hàng tháng mà không làm ảnh hưởng đến việc cách ly dữ liệu khách hàng. Khoản tiết kiệm sẽ ngày càng đáng kể khi doanh nghiệp của bạn có thêm nhiều khách hàng, tạo ra một mô hình tăng trưởng hiệu quả hơn, vừa duy trì bảo mật, vừa loại bỏ sự trùng lặp lãng phí.\n2. Tối ưu hóa chi phí phân phối nội dung của bạn Mạng phân phối nội dung giúp website tải nhanh hơn bằng cách cache nội dung gần với người dùng, nhưng nhiều doanh nghiệp nhỏ lại trả tiền cho phạm vi toàn cầu trong khi khách hàng của họ chỉ tập trung ở một vài khu vực. Việc xem xét lại vị trí địa lý thực tế của người dùng và điều chỉnh chiến lược phân phối nội dung phù hợp có thể mang lại khoản tiết kiệm đáng kể. Ví dụ, nếu doanh nghiệp của bạn chủ yếu phục vụ khách hàng ở Bắc Mỹ và Châu Âu, bạn có thể chọn tùy chọn phân phối theo khu vực trong Amazon CloudFront thay vì sử dụng thiết lập mặc định toàn cầu.\n3. Tự động hóa tác vụ thường lệ bằng AI Thời gian là tiền bạc, đặc biệt với các doanh nghiệp nhỏ nơi nhân sự phải đảm nhận nhiều vai trò cùng lúc. Generative AI hiện nay có thể tự động hóa nhiều tác vụ lặp đi lặp lại, giúp giải phóng nguồn lực để tập trung vào các hoạt động tăng trưởng.\nVí dụ:\nĐội ngũ bán hàng có thể dùng AI để tạo ra các bản đề xuất tùy chỉnh dựa trên những thương vụ thành công trước đó, từ đó giảm đáng kể thời gian dành cho việc soạn thảo tài liệu lặp lại.\nĐội ngũ chăm sóc khách hàng có thể triển khai AI để xử lý các câu hỏi thường gặp, giúp rút ngắn thời gian phản hồi mà vẫn duy trì được giọng điệu thương hiệu trong mọi tương tác với khách hàng.\nBằng cách xác định những tác vụ có tần suất cao và dễ lặp lại trong doanh nghiệp, tự động hóa bằng AI không chỉ giảm chi phí nhân công, mà còn nâng cao tính nhất quán và cho phép nguồn nhân lực giá trị tập trung vào chiến lược và xây dựng mối quan hệ.\nCách tiếp cận này đã chứng minh hiệu quả đối với các công ty như Creative Realities, Inc. Ông Bart Massey, Phó Chủ tịch Điều hành phụ trách Phát triển Phần mềm, cho biết: “Sử dụng Amazon Q Business để xây dựng mô hình riêng cho thông tin sản phẩm của chúng tôi đã giúp rút ngắn thời gian phản hồi RFP và RFI hơn 50%, cho phép chúng tôi phản hồi nhanh hơn trước yêu cầu của khách hàng ngay từ ngày đầu tiên.” Trải nghiệm của họ cho thấy Generative AI có thể giúp tinh giản đáng kể các quy trình kinh doanh, từ đó nâng cao hiệu quả và tốc độ phản hồi trong tương tác với khách hàng.\nXây dựng hiệu quả chi phí trong dài hạn 1. Giảm chi phí phát triển phần mềm Chi phí phát triển phần mềm có thể nhanh chóng tiêu thụ hết ngân sách công nghệ của bạn. Các công cụ hỗ trợ lập trình hiện đại giúp tăng tốc phát triển phần mềm bằng cách gợi ý hoàn thiện mã, phát hiện lỗi sớm và tự động hóa các tác vụ lập trình lặp lại. Amazon Q Developer là ví dụ tiêu biểu cho cách tiếp cận này, giúp giảm chi phí chỉnh sửa bằng việc phát hiện vấn đề trước khi đưa vào môi trường production và cung cấp hướng dẫn theo thời gian thực trong suốt quá trình phát triển. Trợ lý lập trình AI này giúp các developer áp dụng best practices, viết mã an toàn hơn và xử lý sự cố nhanh hơn. Khi được kết hợp với phương pháp Infrastructure as Code (IaC), doanh nghiệp có thể chuẩn hóa môi trường từ khâu phát triển đến khâu sản xuất, loại bỏ các cấu hình thủ công tốn thời gian và rút ngắn thời gian triển khai từ vài ngày xuống chỉ còn vài phút. Những công ty áp dụng các phương pháp này thường đạt được chi phí phát triển thấp hơn đồng thời đẩy nhanh thời gian ra thị trường.\n2. Tự động hóa quản lý hạ tầng Tạo tài nguyên khi cần và xóa chúng khi không sử dụng. Hãy dùng AWS Lambda với lịch trình từ Amazon EventBridge để tự động tắt môi trường phát triển ngoài giờ và khởi động lại trước khi ngày làm việc bắt đầu. Nhờ đó, chi phí cho môi trường không phải sản xuất sẽ giảm đáng kể vì tài nguyên chỉ chạy trong giờ làm việc. Một cách tiếp cận hiệu quả khác là tự động mở rộng (auto scaling) theo chu kỳ kinh doanh dự đoán được, bằng cách sử dụng AWS Auto Scaling để tự động tăng dung lượng trong thời kỳ cao điểm và giảm dung lượng trong thời kỳ ít tải hơn. Những chiến lược tự động hóa này có thể cắt giảm chi phí cho các workload cụ thể.\n3. Xem lại kiến trúc hệ thống Không phải tất cả công nghệ trong doanh nghiệp đều cần mức bảo vệ cao cấp “luôn bật”. Hãy áp dụng phương pháp phân lớp: chỉ đầu tư dự phòng cho các thành phần quan trọng đối diện khách hàng, trong khi các công cụ nội bộ chỉ cần cấu hình tiêu chuẩn.\nVí dụ:\nDoanh nghiệp có thể duy trì khả năng sẵn sàng cao (high-availability) chỉ cho hệ thống hướng tới khách hàng, bằng cách dùng các tùy chọn triển khai linh hoạt từ Amazon Relational Database Service (Amazon RDS).\nCác dự án khách hàng đã hoàn thành có thể được chuyển sang lớp lưu trữ lưu trữ lâu dài (archival tiers) của Amazon Simple Storage Service (Amazon S3) nhưng vẫn duy trì khả năng truy cập, từ đó giảm chi phí.\nVới các doanh nghiệp có chu kỳ bận rộn dự đoán được, dịch vụ Amazon Aurora Serverless sẽ tự động điều chỉnh tài nguyên trong giờ cao điểm và giảm khi yên ắng, giúp tiết kiệm so với việc duy trì dung lượng tối đa liên tục.\nBằng cách điều chỉnh độ tin cậy của hệ thống cho phù hợp với nhu cầu thực tế, hầu hết các doanh nghiệp nhỏ có thể giảm chi phí cloud mà không ảnh hưởng đến dịch vụ quan trọng.\nKết luận Tối ưu hóa chi phí cloud không đồng nghĩa với việc hy sinh chất lượng hay tính năng. Bằng việc triển khai các chiến lược này, doanh nghiệp nhỏ có thể giảm chi phí trong khi vẫn tận dụng được công nghệ mạnh mẽ để thúc đẩy tăng trưởng và đổi mới. Hãy bắt đầu từ những bước đơn giản như tối ưu hóa lưu trữ và quản lý chứng chỉ, sau đó tiến đến các cách tiếp cận nâng cao hơn như chia sẻ tài nguyên mạng và tự động hóa bằng AI. Mỗi bước đi đều đóng góp vào tiết kiệm dài hạn và nâng cao hiệu quả.\nHãy nhớ rằng, tối ưu hóa chi phí là một hành trình liên tục. Khi doanh nghiệp phát triển và thay đổi, hãy thường xuyên đánh giá lại nhu cầu công nghệ và điều chỉnh chiến lược cho phù hợp. Với kế hoạch chu đáo và triển khai hợp lý, bạn có thể xây dựng một nền tảng công nghệ tiết kiệm chi phí, có khả năng mở rộng, hỗ trợ các mục tiêu kinh doanh cả hôm nay và trong tương lai.\nĐể bắt đầu hành trình cắt giảm chi phí với AWS, hãy liên hệ với chuyên viên tư vấn bán hàng.",
    "description": "Tiết kiệm nhờ công nghệ: Những cách sáng tạo để cắt giảm chi phí cho doanh nghiệp nhỏ của bạn Henrique Trevisan, Jonathan Woods, and Vince Anderson | 23/4/2024 | in Best Practices, Permalink\nViệc vận hành một doanh nghiệp nhỏ có nghĩa là tận dụng tối đa từng đô la trong khi vẫn duy trì dịch vụ chất lượng cao. Khi doanh nghiệp và nền tảng đám mây của bạn sử dụng mở rộng, bạn phải tìm cách để quản lý nguồn lực công nghệ một cách hiệu quả để bảo vệ lợi nhuận của bạn. Trong môi trường kinh tế thách thức ngày nay, tối ưu chi phí đã trở thành là ưu tiên hàng đầu của chủ doanh nghiệp những người muốn cắt giảm chi phí mà không cần hy sinh hiệu năng, bảo mật và trải nghiệm người dùng.",
    "tags": [],
    "title": "Blog 2",
    "uri": "/vi/3-blogstranslated/3.2-blog2/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 2: Tìm hiểu kiến trúc VPC cơ bản và các thành phần quan trọng có liên quan Thực hiện các bài lab trong module 2 Đọc tìm hiểu cuốn Aws advanced network Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu thêm các thuật ngữ có liên quan tới bài thực hành VPC 15/9/2025 15/9/2025 https://viblo.asia/p/tim-hieu-ve-aws-phan-1-vpc-virtual-private-cloud-924lJGv05PM 3 - Thực hành: + lab03: Amazon VPC and AWS Site-to-Site VPN Workshop 16/9/2025 16/9/2025 http://000003.awsstudygroup.com/ 4 - Tìm hiểu cách làm bài tập thiết lập DNS với route 53 Thực hành: + lab10: Set up Hybrid DNS with Route 53 Resolver 17/9/2025 17/9/2025 https://000010.awsstudygroup.com/ 5 - Tham gia cloud day vietnam tại thành phố Hồ Chí Minh 18/09/2025 18/9/2025 6 - Dịch blogs - Viết worklog và báo cáo event 1 19/09/2025 19/9/2025 https://aws.amazon.com/vi/blogs/smb/tech-savvy-savings-innovative-ways-to-cut-costs-in-your-small-business/ 7 - Thực hành: + lab20: Thiết lập AWS Transit Gateway + lab19: Thiết lập VPC Peering 20/09/2025 20/9/2025 https://000020.awsstudygroup.com/vi/ https://000019.awsstudygroup.com/vi/ Kết quả đạt được tuần 2: Hiểu được về dịch vụ VPC và cách để tạo ra 1 mạng riêng ảo trên AWS\nBiết cách cấu hình cho security group, subnet, route table\nTạo ra được EC2 đầu tiên\nXây dựng được hệ thống hyrid DNS dựa vào ROUTE53\nTham gia event cloud day vietnam và học thêm về migration, modernization\nBiết cách dọn dẹp tài nguyên không còn dùng đến",
    "description": "Mục tiêu tuần 2: Tìm hiểu kiến trúc VPC cơ bản và các thành phần quan trọng có liên quan Thực hiện các bài lab trong module 2 Đọc tìm hiểu cuốn Aws advanced network Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu thêm các thuật ngữ có liên quan tới bài thực hành VPC 15/9/2025 15/9/2025 https://viblo.asia/p/tim-hieu-ve-aws-phan-1-vpc-virtual-private-cloud-924lJGv05PM 3 - Thực hành: + lab03: Amazon VPC and AWS Site-to-Site VPN Workshop 16/9/2025 16/9/2025 http://000003.awsstudygroup.com/ 4 - Tìm hiểu cách làm bài tập thiết lập DNS với route 53 Thực hành: + lab10: Set up Hybrid DNS with Route 53 Resolver 17/9/2025 17/9/2025 https://000010.awsstudygroup.com/ 5 - Tham gia cloud day vietnam tại thành phố Hồ Chí Minh 18/09/2025 18/9/2025 6 - Dịch blogs - Viết worklog và báo cáo event 1 19/09/2025 19/9/2025 https://aws.amazon.com/vi/blogs/smb/tech-savvy-savings-innovative-ways-to-cut-costs-in-your-small-business/ 7 - Thực hành: + lab20: Thiết lập AWS Transit Gateway + lab19: Thiết lập VPC Peering 20/09/2025 20/9/2025 https://000020.awsstudygroup.com/vi/ https://000019.awsstudygroup.com/vi/ Kết quả đạt được tuần 2: Hiểu được về dịch vụ VPC và cách để tạo ra 1 mạng riêng ảo trên AWS",
    "tags": [],
    "title": "Tuần 2",
    "uri": "/vi/1-worklog/1.2-week2/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Đẩy nhanh làn sóng khởi nghiệp AI thế hệ tiếp theo Swami Sivasubramanian | 13/06/2024 | in AWS for Startups, Featured, Startup, Startup Spotlight | Permalink\nTừ ngày đầu tiên, AWS đã giúp các công ty khởi nghiệp hiện thực hóa ý tưởng của họ bằng cách dân chủ hóa quyền truy cập tới chủ hóa quyền truy cập vào công nghệ đang hỗ trợ một số doanh nghiệp lớn nhất trên thế giới, bao gồm cả Amazon. Mỗi năm kể từ 2020, chúng tôi đã cung cấp cho các công ty khởi nghiệp gần 1 tỷ đô la tín dụng khuyến mãi AWS. Không có gì ngẫu nhiên khi 80% kỳ lân của thế giới sử dụng AWS. Tôi rất may mắn khi chứng kiến sự phát triển của các công ty khởi nghiệp trong suốt thời gian làm việc tại AWS - các công ty như Netflix, Wiz và Airtasker. Và tôi rát hào hứng với tốc độ nhanh chóng mà các công ty khởi nghiệp ứng dụng công nghệ trí tuệ nhân tạo (AI) và cách mà công nghệ này đang tạo ra một thế hệ khởi nghiệp hoàn toàn mới.\nCác công ty khởi nghiệp AI có thể chuyển đổi các ngành công nghiệp và định hình tương lai, đó là lý do tại sao hôm nay chúng tôi công bố cam kết 230 triệu đô la để thúc đẩy cho sự sáng tạo của ứng dụng công nghệ AI bởi các công ty khởi nghiệp trên toàn thế giới. Chúng tôi hứng thú với việc hợp tác với các công ty khởi nghiệp có tầm nhìn, nuôi dưỡng sự phát triển của họ, và mở ra các cơ hội mới. Ngoài sự đầu tư tiền tệ này, hôm nay chúng tôi cũng thông báo sự hiện AWS Generative AI Accelerator hằng năm lần thứ 2 hợp tác với NVIDIA. Chương trình kết hợp toàn cầu kéo dài 10 tuần này được thiết kế để thúc đẩy làn sóng khởi nghiệp AI tiếp theo. Năm nay, chúng tôi đang mở rộng chương trình lên gấp 4 để phục vụ 80 công ty khởi nghiệp một cách toàn diện. Những người tham gia được chọn sẽ nhận mỗi người lên tới 1 triệu đô la tín dụng khuyến mãi AWS để thúc đẩy cho sự phát triển của họ và mở rộng những thứ cần thiết. Chương trình cũng cung cấp sự hỗ trợ đưa ra thị trường cũng như là cố vấn kinh doanh và kỹ thuật. Những người tham gia sẽ khai thác vào một mạng bao gồm những chuyên gia trong lĩnh vực từ AWS cũng như là các đối tác chính của AWS như NVIDIA, Meta, Mistral AI, và các công ty đầu tư mạo hiểm đang rót vốn vào AI.\nXây dựng nền tảng đám mây với AI Ngoài chương trình đó, AWS cam kết tạo điều kiện cho các công ty khởi nghiệp ở mọi quy mô và các nhà phát triển ở mọi trình độ kỹ năng xây dựng và mở rộng các ứng dụng AI với bộ khả năng toàn diện nhất trên 3 lớp của ngăn xếp AI. Ở tầng cuối cùng ở ngăn xếp, chúng tôi cung cấp hạ tầng để huấn luyện mô hình ngôn ngữ lớn (LLMs) và mô hình nền tảng (FMs) và đưa ra các suy luận hoặc dự đoán. Nó bao gồm GPUs NVIDIA tốt nhất và phần mềm tối ưu hóa GPU, chip tùy chỉnh máy học (ML) bao gồm AWS Trainium và AWS Inferentia, cũng như là Amazon SageMaker, cái làm đơn giản hóa đáng kể quá trình phát triển ML, Amazon Bedrock giúp cho các startup xây dựng các ứng dụng AI tạo ra an toàn, tùy chỉnh và trách nhiệm bằng cách sử dụng LLMs và các FM khác từ các công ty AI dẫn đầu. Và ở tầng trên cùng của ngăn xếp, chúng tôi có Amazon Q, trợ lý AI có khả năng tạo ra năng lực tốt nhất cho việc thúc đẩy phát triển phần mềm và tận dụng toàn bộ dữ liệu nội bộ cảu công ty.\nCác khách hàng đang đổi mới bằng cách sử dụng các công nghệ trên toàn bộ stack. Ví dụ như là, trong suốt thời gian tôi ở hội nghị VivaTech ở Paris tháng trước, tôi đã ngồi cùng Michael Chen, Phó chủ tịch Liên minh chiến lược tại PolyAI, công ty cung cấp các giải pháp AI giọng nói tùy chỉnh cho các doanh nghiệp. PolyAI phát triển mô hình biến văn bản thành giọng nói tự nhiên sử dụng Amazon SageMaker. Và họ xây dựng trên Amazon Bedrock để đảm bảo các hoạt động AI có trách nhiệm và đạo đức. Họ dùng Amazon Connect để tích hợp giọng nói AI của họ vào việc hoạt động chăm sóc khách hàng.\nỞ tầng cuối của ngăn xếp, NinjaTech sử dụng các cong chip Trainium và Inferentia2, thuộc về Amazon SageMaker để xây dựng, huấn luyện, và mở rộng tùy chỉnh các tác nhân AI. Từ việc tiến hành nghiên cứu tới việc lên lịch gắp mặt, các tác nhân AI này giúp tiết kiệm thời gian và tiền bạc cho người dùng của NinjaTech bằng cách đưa sức mạnh của AI vào quy trình làm việc hằng ngày của họ. Tôi gần đây có ngồi cùng Sam Naghshineh, đồng sáng lập và giám đốc công nghệ, để thảo luận về cách tiếp cận này giúp họ tiết kiệm thời gian và tài nguyên cho người dùng như thế nào.\nLeonardo.AI, một công ty khởi nghiệp từ nhóm AWS Generative AI Accelerator năm 2023, cũng đang khai thác khả năng của AWS Inferentia2 để giúp các nghệ sĩ và chuyên gia tạo ra các sản phẩm hình ảnh chất lượng cao với tốc độ và độ nhất quán vượt trội. Bằng cách giảm chi phí suy luận mà không làm giảm hiệu suất, Leonardo.AI có thể cung cấp những tính năng AI tạo sinh tiên tiến nhất với mức giá dễ tiếp cận hơn.\nCác công ty khởi nghiệp AI dẫn đầu, bao gồm Perlexity, Hugging Face, AI21 Labs, Articul8, Luma AI, Hippocratic AI, Recursal AI, và Datology AI đang xây dựng, huấn luyện, và phát triển mô hình của họ trên Amazon SageMaker. Ví dụ, Hugging Face đã sử dụng Amazon SagaMaker HyperPod, một tính năng giúp thúc đẩy việc huấn luyện mô hình tăng lên đến 40%, để tạo ra FMs mã nguồn mở mới. Tính năng phục hồi công việc tự động giúp giảm thiểu sự gián đoạn trong suốt quá trình huấn luyện FM, tiết kiệm cho họ 100 giờ mỗi lần huấn luyện trong 1 năm.\nỞ tầng giữa, Perplexity tận dụng Amazon Bedrock với Anthropic Claude 3 để xây dựng công cụ tìm kiếm hỗ trợ AI của họ. Bedrock đảm bảo bảo vệ dữ liệu mạnh mẽ, sự liên kết về mặt đạo đức thông qua việc chọn lọc nội dung, và mở rộng phát triển của Claude 3. Trong khi Nexxiot, một nhà đổi mới trong giải pháp vận tải và chuỗi cung ứng, đã nhanh chóng chuyển giải pháp trợ lý AI Scope của mình sang Amazon Bedrock với Anthropic Claude để cung cấp cho khách hàng những thông tin chi tiết theo thời gian thực, trực quan nhất về tài sản vận tải của họ.\nỞ tầng trên cùng, Amazon Q Developer giúp các nhà phát triển xây dựng, kiểm thử, và triển khai các ứng dụng nhanh hơn và hiệu quả hơn, cho phép họ tập trung năng lượng của mình vào việc thúc đẩy đổi mới. Ancileo, một nhà cung cấp bảo hiểm SaaS cho các công ty bảo hiểm, công ty tái bảo hiểm, môi giới và đối tác liên kết, sử dụng Amazon Q Developer để giảm thời gian cho việc giải quyết các vấn đề liên quan tới coding 30%, và đang tích hợp hệ thống bán vé và tài liệu với Amazon Q để tăng tốc quá trình tiếp nhận và cho phép mọi người ở công ty nhanh chóng tìm ra câu trả lời của họ. Amazon Q Business cho phép mọi người tại một công ty khởi nghiệp trở nên hướng dữ liệu hơn, từ đó đưa ra các quyết định tốt hơn và nhanh hơn dựa trên tri thức tập thể của tổ chức. Brightcove, một nhà cung cấp hàng đầu về dịch vụ video trên nền tảng đám mây, đã triển khai Amazon Q Business để tinh gọn quy trình hỗ trợ khách hàng, giúp đội ngũ tăng tốc độ phản hồi, cung cấp dịch vụ cá nhân hóa hơn, và cuối cùng là nâng cao trải nghiệm khách hàng.\nTài nguyên cho công ty khởi nghiệp AI Tương lai của AI phụ thuộc vào những ai hành động ngay bây giờ, thời gian nhận đơn cho chương trình AWS Generative AI Accelerator mở từ 13 tháng 6 đến 19 thangs7 năm 2024, và chúng tôi sẽ lựa chọn một lớp học toàn cầu gồm những startup AI tạo sinh tiềm năng nhất. Đừng bỏ lỡ cơ hội độc đáo này để tái định nghĩa những gì có thể với AI tạo sinh — hãy nộp đơn ngay hôm nay!\nCác tài nguyên hữu ích khác bao gồm:\nBạn có thể sử dụng tín dụng AWS Activate cho Amazon Bedrock để trải nghiệm với FMs, cùng với một loạt các khả năng cần thiết để xây dựng các ứng dụng AI tạo ra có trách nhiệm với tính bảo mật và quyền riêng tư.\nKhám phá sâu hơn bằng cách khám phá không gian cộng đồng Generative AI của chúng tôi để biết nội dung kĩ thuật , tầm nhìn, và kết nối với các người xây dựng khác. AWS cũng cung cấp đào tạo miễn phí để giúp cho lực lượng lao động hiện tại và tương lai tận dụng các công cụ AI tạo ra của Amazon. Cho những ai hứng thú với việc nghiên cứu để xây dựng generative AI trên AWS, khám phá kế hoạch học tập AI toàn diện cho nhà phát triển để đạt được những kỹ năng cần thiết cho việc tạo ra ứng dụng tiên tiến\nNVIDIA cung cấp NVIDIA Inception, một chương trình miễn phí được thiết kế để giúp công ty khởi nghiệp phát triển nhanh hơn thông qua công nghệ tiên tiến, các cơ hội để kết nối với các nhà đầu tư mạo hiểm, và tiếp cận với tài nguyên công nghệ mới nhất đến từ NVIDIA.\nNộp đơn ngay, khám phá các nguồn lực và tham gia cuộc cách mạng AI tạo ra cùng AWS.\nTài nguyên bổ sung Chuỗi bài việc trên Twitch: Hãy cùng vận hành - với AWS! Trí tuệ nhân tạo\nChương trình thúc đẩy trí tuệ nhân tạo AI: Đăng ký ngay\nTAGS: Thúc đẩy, Khởi nghiệp AWS",
    "description": "Đẩy nhanh làn sóng khởi nghiệp AI thế hệ tiếp theo Swami Sivasubramanian | 13/06/2024 | in AWS for Startups, Featured, Startup, Startup Spotlight | Permalink\nTừ ngày đầu tiên, AWS đã giúp các công ty khởi nghiệp hiện thực hóa ý tưởng của họ bằng cách dân chủ hóa quyền truy cập tới chủ hóa quyền truy cập vào công nghệ đang hỗ trợ một số doanh nghiệp lớn nhất trên thế giới, bao gồm cả Amazon. Mỗi năm kể từ 2020, chúng tôi đã cung cấp cho các công ty khởi nghiệp gần 1 tỷ đô la tín dụng khuyến mãi AWS. Không có gì ngẫu nhiên khi 80% kỳ lân của thế giới sử dụng AWS. Tôi rất may mắn khi chứng kiến sự phát triển của các công ty khởi nghiệp trong suốt thời gian làm việc tại AWS - các công ty như Netflix, Wiz và Airtasker. Và tôi rát hào hứng với tốc độ nhanh chóng mà các công ty khởi nghiệp ứng dụng công nghệ trí tuệ nhân tạo (AI) và cách mà công nghệ này đang tạo ra một thế hệ khởi nghiệp hoàn toàn mới.",
    "tags": [],
    "title": "Blog 3",
    "uri": "/vi/3-blogstranslated/3.3-blog3/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập",
    "content": "Blog 1 - Công nghệ dạy về sự đồng cảm? Cách mà mpathic sử dụng AI để giúp chúng ta lắng nghe nhau Điều gì sẽ xảy ra nếu trí tuệ nhân tạo (AI) có thể tăng cường khả năng lắng nghe và kết nối thực sự với người khác của chúng ta? Điều gì sẽ xảy ra nếu công nghệ có thể khai thác những trải nghiệm sống chung của chúng ta và giúp chúng ta trở nên nhân văn hơn với nhau? Đây là những câu hỏi mà Tiến sĩ Grin Lord, nhà tâm lý học lâm sàng và nhà sáng lập công ty phân tích hội thoại mpathic, đã dành 15 năm theo đuổi.\nBlog 2 - Tiết kiệm nhờ công nghệ: những cách sáng tạo để cắt giảm chi phí cho doanh nghiệp nhỏ của bạn Khám phá các chiến lược thiết thực để giảm chi phí cho doanh nghiệp nhỏ của bạn thông qua quản lý đám mây thông minh, tối ưu hóa lưu trữ và tự động hóa AI. Tìm hiểu cách tiết kiệm chi phí mà vẫn đảm bảo chất lượng.\nBlog 3 - Đẩy nhanh làn sóng khởi nghiệp AI thế hệ tiếp theo Ngay từ những ngày đầu, AWS đã giúp các startup hiện thực hóa ý tưởng của mình bằng cách dân chủ hóa quyền truy cập vào công nghệ đang hỗ trợ một số doanh nghiệp lớn nhất thế giới, bao gồm cả Amazon. Các startup này có khả năng chuyển đổi ngành công nghiệp và định hình tương lai, đó là lý do tại sao hôm nay chúng tôi công bố cam kết tài trợ 230 triệu đô la để thúc đẩy việc tạo ra các ứng dụng AI tạo sinh bởi các startup trên toàn thế giới. Đọc để tìm hiểu cách đăng ký trở thành thành viên của chương trình toàn cầu này.\nBlog 4 - Mở rộng môi trường phát triển của Cloudera: Tận dụng Amazon EKS, Karpenter, Bottlerocket và Cilium cho mô hình Hybrid Cloud Bài viết này được đồng sáng tác bởi Shreelola Hegde, Sriharsha Devineni và Lee Watterworth từ Cloudera. Cloudera là công ty hàng đầu thế giới về quản lý dữ liệu doanh nghiệp, phân tích và AI. Nền tảng Cloudera cho phép các tổ chức quản lý, xử lý và phân tích các tập dữ liệu khổng lồ, giúp các doanh nghiệp trong nhiều ngành như tài chính, chăm sóc sức khỏe, sản xuất, và viễn thông đẩy nhanh việc áp dụng AI/ML và mở khóa thông tin chi tiết theo thời gian thực.\nBlog 5 - Tạo ứng dụng đa vùng với dịch cụ AWS - Phần 1, Tính toán, Mạng và Bảo mật Nhiều dịch vụ AWS có các tính năng để giúp bạn xây dựng và quản lý một kiến trúc đa vùng nhưng việc xác định những khả năng đó trên hơn 200 dịch vụ có thể rất khó khăn. Đây là chuỗi blog gồm 3 phần, chúng tôi lọc thông qua hơn 200 dịch vụ và tập trung vào những thứ có tính năng cụ thể để hỗ trợ bạn trong việc xây dụng các ứng dụng đa vùng. Trong phần 1, chúng ta sẽ xây dựng một nền tảng với các dịch vụ bảo mật, mạng và tính toán của AWS.\nBlog 6 - Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên ArgoCD là một bộ công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernets một cách khai báo, sử dụng Git là nguồn thông tin đáng tin cậy duy nhất. Bộ tính năng mạnh mẽ của nó bao gồm hệ thống đồng bộ tự động, hỗ trợ khôi phục, phát hiện sai lệch, chiến lược triển khai nâng cao, TÍch hợp RBAC, và hỗ trợ đa cụm (multi-cluster), khiến nó trẻ thành giải pháp được ưa chuộng cho việc triển khai ứng dụng trên Kubernetes. Tuy nhiên, khi các tổ chức mở rộng quy mô, một vài điểm khó khăn và thách thử vận hành bắt đầu xuất hiện.\nBlog 7 - Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa Hôm nay, chúng tôi vui mừng thông báo về phiên bản 1.0 của Strands Agents SDK, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho sản xuất. Strands Agents là một SDK mã nguồn mở, áp dụng phương pháp model-driven, giúp bạn xây dựng và vận hành các agent AI chỉ trong vài dòng code. Strands có khả năng mở rộng từ các trường hợp sử dụng agent đơn giản đến phức tạp, cũng như từ phát triển cục bộ đến triển khai trong môi trường production.\nBlog 8 - Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2 Việc phân tích lượng dữ liệu genomic và multiomic ngày càng gia tăng đòi hỏi các giải pháp tính toán hiệu quả, có khả năng mở rộng và tiết kiệm chi phí. Amazon Web Services (AWS) tiếp tục hỗ trợ các khối lượng công việc này thông qua các dịch vụ tính toán tăng tốc bằng FPGA như các instance Amazon EC2 F2.",
    "description": "Blog 1 - Công nghệ dạy về sự đồng cảm? Cách mà mpathic sử dụng AI để giúp chúng ta lắng nghe nhau Điều gì sẽ xảy ra nếu trí tuệ nhân tạo (AI) có thể tăng cường khả năng lắng nghe và kết nối thực sự với người khác của chúng ta? Điều gì sẽ xảy ra nếu công nghệ có thể khai thác những trải nghiệm sống chung của chúng ta và giúp chúng ta trở nên nhân văn hơn với nhau? Đây là những câu hỏi mà Tiến sĩ Grin Lord, nhà tâm lý học lâm sàng và nhà sáng lập công ty phân tích hội thoại mpathic, đã dành 15 năm theo đuổi.",
    "tags": [],
    "title": "Các bài blog đã dịch",
    "uri": "/vi/3-blogstranslated/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 3: Tìm hiểu về Dịch vụ Compute VM trên AWS Thực hiện triển khai được ứng dụng trên EC2, tạo backup và dùng cloudwatch để theo dõi hệ thống Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xem video bài giảng về dịch vụ Compute VM trên AWS - Dịch blogs cho tuần 3 22/9/2025 22/9/2025 https://aws.amazon.com/vi/blogs/startups/accelerating-the-next-wave-of-generative-ai-startups/ 3 - Thực hành: + lab04: Khởi tạo và tìm hiểu các tính năng cơ bản của Amazon EC2 23/9/2025 23/9/2025 https://000004.awsstudygroup.com/ 4 - Thực hành: + lab04 mục 8: Giới hạn sử dụng tài nguyên bằng dịch vụ IAM + lab02: Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 24/9/2025 24/9/2025 https://000004.awsstudygroup.com/vi/8-costusagegovernance/ https://000002.awsstudygroup.com/vi/ 5 - Thực hành: + lab08: Sử dụng CloudWatch 25/9/2025 25/9/2025 https://000008.awsstudygroup.com/ 6 - Thực hành: + lab06: Triển khai ứng dụng FCJ Management với Auto Scaling Group + lab13: Triển khai aws backup cho hệ thống 26/9/2025 26/9/2025 https://000006.awsstudygroup.com/ https://000013.awsstudygroup.com/ Kết quả đạt được tuần 3: Hiểu được về dịch vụ Compute VM trên AWS\nBiết cách triển khai 1 ứng dụng đơn giản lên máy chủ AWS Linux\nQuản trị quyền truy cập vào tài nguyên\nTriển khai các chiến lược scaling hệ thống để cân bằng tải cho hệ thống\nSử dụng CloudWatch để theo dõi tình hình của hệ thống\nTriển khai AWS Backup cho hệ thống\nBiết giới hạn quyền truy cập vào tài nguyên bằng IAM",
    "description": "Mục tiêu tuần 3: Tìm hiểu về Dịch vụ Compute VM trên AWS Thực hiện triển khai được ứng dụng trên EC2, tạo backup và dùng cloudwatch để theo dõi hệ thống Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xem video bài giảng về dịch vụ Compute VM trên AWS - Dịch blogs cho tuần 3 22/9/2025 22/9/2025 https://aws.amazon.com/vi/blogs/startups/accelerating-the-next-wave-of-generative-ai-startups/ 3 - Thực hành: + lab04: Khởi tạo và tìm hiểu các tính năng cơ bản của Amazon EC2 23/9/2025 23/9/2025 https://000004.awsstudygroup.com/ 4 - Thực hành: + lab04 mục 8: Giới hạn sử dụng tài nguyên bằng dịch vụ IAM + lab02: Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 24/9/2025 24/9/2025 https://000004.awsstudygroup.com/vi/8-costusagegovernance/ https://000002.awsstudygroup.com/vi/ 5 - Thực hành: + lab08: Sử dụng CloudWatch 25/9/2025 25/9/2025 https://000008.awsstudygroup.com/ 6 - Thực hành: + lab06: Triển khai ứng dụng FCJ Management với Auto Scaling Group + lab13: Triển khai aws backup cho hệ thống 26/9/2025 26/9/2025 https://000006.awsstudygroup.com/ https://000013.awsstudygroup.com/ Kết quả đạt được tuần 3: Hiểu được về dịch vụ Compute VM trên AWS",
    "tags": [],
    "title": "Tuần 3",
    "uri": "/vi/1-worklog/1.3-week3/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Mở rộng môi trường phát triển của Cloudera: Tận dụng Amazon EKS, Karpenter, Bottlerocket và Cilium cho mô hình Hybrid Cloud Harpreet Virk and Padma Iyer | 26/09/2025 | in Advanced (300), Amazon Elastic Kubernetes Service, Best Practices, Containers, Graviton, Migration, Migration Acceleration Program (MAP) | Permalink |\nBài viết này được viết cùng với Shreelola Hegde,Sriharsha Devineni và Lee Watterworth đến từ Cloudera\nCloudera là một công ty hàng đầu thế giới về quản trị dữ liệu doanh nghiệp, phân tích và AI. Nền tảng Cloudera cho phép các tổ chức có thể quản lý, xử lý và phân tích các tập dữ liệu lớn, giúp các doanh nghiệp trong nhiều ngành công nghiệp như tài chính, chăm sóc sức khỏe, sản xuất, và viễn thông đẩy nhanh việc áp dụng AI/ML và mở khóa thông tin chi tiết theo thời gian thực.\nYếu tổ then chốt để đạt dược thành công của nền tảng là môi trường phát triển, nơi mà các nhà phát triển có thể xây dựng và kiểm thử tính năng mới để phát hành. Môi trường được xây dựng trên Kubernets, đã đối mặt với nhiều thách thức trong hệ thống on-premises, đặc biệt là trong khả năng mở rộng và tận dụng tài nguyên.\nBài viết đề cập đến cách Cloudera đã hiện đại hóa hoạt động phát triển của họ bằng việc áp dụng một hyrid cloud được xây dựng bởi Amazon Elastic Kubernetes Service (Amazon EKS). Chiến lượt này cân bằng giữa dung lượng hiện có của môi trường on-premises với khả năng co giãn của cloud trong khi vẫn tận dụng các cải tiến như Karpenter, Bottlerocker, và Cilium để tối ưu việc mở rộng, bảo mật và hiệu quả về chi phí.\nThách thức vận hành đối với On-Premises Môi trường phát triển gặp những thách thức khi chạy on-premises: Môi trường yêu cầu phải mở rộng và thu hẹp thường xuyên nhưng bị hạn chế bởi dung lượng cố định Quá trình xây dụng và kiểm thử cho dịch vụ như Apache Spark, Hive, và HBase yêu cầu container với dụng lượng lên đến 64GB RAM và 32 vCPu, nhanh chóng vượt quá nguyền tài nguyên có sẵn Các yêu cầu pull trong các sprints lập trình cường độ cao tăng lên 300% dẫn tới thời gian xây dựng tăng thêm 45 phút, tạo ra các nút thắt trong CI/CD pipeline điều này làm chậm đáng kể tốc độ phát triển. Điều này, lần lượt, làm trì hoãn việc bàn giao tính năng, gây rủi ro cho lịch phát hành, đồng thời làm tăng chi phí hạ tầng và thời gian nhàn rỗi của lập trình viên. Thiết kế ứng dụng cũng liên quan đến việc truy xuất và lưu trữ artifacts và datasets từ Amazon S3, điều này gây ra độ trễ cho các agent on-premises, làm kéo dài thêm các chu kỳ build và test. Những hạn chế này đã tạo ra các nút thắt trong pipeline phát triển và nhấn mạnh nhu cầu về khả năng co giãn vượt ra ngoài các cụm on-premises. Giải pháp tổng quan Cloudera đã giải quyết các thách thức bằng cách áp dụng mô hình hyrid cloud trong đó khối lượng công việc có thể dự đoán được đã được duy trì trong on-premises và khối lượng công việc động được đưa lên AWS. Kiến trúc này kết hợp sự co giãn của AWS với cơ sở hạ tầng on-premises đã được thiết lập của Cloudera, mang lại khả năng mở rộng liền mạch, giảm sự độ trễ và tối ưu hóa chi phí.\nKiến trúc bật cao của môi trường phát triển trong AWS\nKiến trúc Kubernets hiện đại cung cấp những lợi ích dưới đây:\nSự co giãn với Amazon EKS và Karpenter: Cloudera, sử dụng Karpenter, để có thể mở rộng khối lượng công việc của họ từ một số node lên vài nghìn trong một vài phút và cũng có thể thu hẹp khi có nhu cầu cắt giảm. Điều này đảm bảo việc mở rộng hiểu quả trong các đợt tăng đột biến, đồng thời loại bỏ lãng phí tài nguyên khi khối lượng công việc thấp. Điều này cũng cho phép nhiều yêu cầu pull được chạy song song mà không cần đợi tài nguyên, giúp những nhà phát triển có thời gian phản hồi nhanh hơn và cải thiện tốc độ phát hành. Việc cấp phát thông minh đảm bảo rằng các instance tính toán luôn phù hợp với yêu cầu khối lượng công việc, từ đó tăng tỷ lệ sử dụng tài nguyên và giảm chi phí lên đến 40%.\nXử lý các container lớn với Karpenter: Các công việc build và test yêu cầu các container lớn ngay lập tức được ghép với tài nguyên tính toán tối ưu thông qua cơ chế cấp phát node thông minh của Karpenter. Khả năng co giãn theo thời gian thực này đảm bảo không có trễ hay xung đột tài nguyên.\nTăng cường bảo mật với Bottlerocket: Hệ điều hành dựa trên Linux này còn cải thiện quá trình mở rộng bằng cách cung cấp một môi trường tối ưu cho container với chi phí hệ điều hành tối thiểu. Hệ thống tệp bất biến tăng cường bảo mật bằng cách ngăn chặn các thay đổi trái phép, trong khi các cập nhật nguyên tử (atomic updates) giúp đơn giản hóa việc vá hệ thống và giảm thời gian bảo trì. Sự thay đổi này làm giảm bề mặt tấn công của môi trường phát triển đi 60%, tinh giản việc vá lỗi nhờ các cập nhật nguyên tử, và tăng hiệu quả sử dụng tài nguyên tính toán 35%.\nGiảm thời gian build với Bottlerocket và Amazon Elastic Block Store snapshot Amazon EBS: Thời gian khởi chạy pod giảm từ 30 phút xuống chỉ còn vài giây nhờ sử dụng Bottlerocket và snapshot Amazon EBS để tiền tải trước các hình ảnh lớn. Cải tiến này giúp lập trình viên bắt đầu các build mới gần như ngay lập tức, cải thiện năng suất, và các đỉnh pull request không còn tạo ra nút thắt.\nMở rộng mạng lưới với Cilium: Hạ tầng mạng được hiện đại hóa nhờ Cilium, cung cấp bảo mật dựa trên nhận dạng, quan sát nâng cao ở mức pod, và mạng dựa trên eBPF. Bằng cách triển khai quản lý địa chỉ IP linh hoạt, Cilium cho phép Cloudera mở rộng trên 10.000 workloads mà không gặp vấn đề cạn kiệt IP, đồng thời cung cấp tầm nhìn rõ ràng về mạng ở mức pod.\nLoại bỏ lãng phí tài nguyên nhàn rỗi với AWS Graviton và Flex instances: Graviton và Flex instances đóng vai trò quan trọng trong tối ưu chi phí và hiệu năng. Graviton mang lại lợi ích hiệu năng-giá tốt cho workloads dựa trên ARM, trong khi Flex instances tăng hiệu quả cho các tác vụ biên dịch x64. Kết hợp lại, các tùy chọn tính toán này giảm gần một phần ba chi phí vận hành và tối đa 40% chi phí hạ tầng, đảm bảo Cloudera cân bằng giữa hiệu suất và chi phí cho các nhu cầu workload đa dạng.\nGiải quyết độ trễ S3 với tích hợp native cloud: Chạy build trên Amazon EKS giảm độ trễ tới Amazon S3 xuống mức mili giây, giúp tăng tốc việc truy xuất artifacts. Điều này còn mang lại lợi ích bổ sung là giảm 30% chi phí truyền tải mạng.\nGiải pháp tổng thể này không chỉ giải quyết từng nút thắt mà còn tạo ra một nền tảng có khả năng mở rộng linh hoạt, vận hành an toàn, và tối ưu chi phí trên toàn bộ môi trường hybrid.\nKết quả kinh doanh Việc áp dụng môi trường hybrid Kubernetes đã biến đổi hoạt động phát triển của Cloudera. Thời gian chu kỳ build và test được cải thiện 50%, giúp giao hàng các tính năng và cải tiến mới nhanh hơn. Khả năng mở rộng từ 10 lên hơn 1.000 node chỉ trong vài phút đã cung cấp cho lập trình viên quyền truy cập đáng tin cậy vào tài nguyên cần thiết, loại bỏ các nút thắt trong thời điểm nhu cầu cao. Bằng cách tối ưu hóa truyền dữ liệu với Amazon S3, chi phí mạng giảm 30% và độ trễ giảm xuống mili giây. Việc mở rộng thông minh và lựa chọn compute phù hợp với khối lượng công việc đã giảm chi phí hạ tầng 40%. Bottlerocket giảm bề mặt tấn công 60% và tăng hiệu quả sử dụng tài nguyên tính toán 35%.\nNhững cải tiến này không chỉ tăng cường bảo mật, mà còn giải phóng các kỹ sư khỏi việc quản lý hạ tầng, cho phép họ tập trung vào phát triển cốt lõi.\nKết luận Việc triển khai thành công của Cloudera minh chứng sức mạnh biến đổi của stack container của AWS – bao gồm Amazon EKS, Karpenter và Bottlerocket. Môi trường Kubernetes được hiện đại hóa đã mang lại khả năng mở rộng liền mạch, tăng cường bảo mật, và tối ưu quản lý chi phí, đồng thời cung cấp hiệu năng tối đa cho các workloads động. Hành trình của Cloudera chứng minh cách tích hợp các giải pháp AWS chuyên biệt có thể cải thiện đáng kể quản lý hạ tầng, giảm tải vận hành, và tăng tốc năng suất của lập trình viên.\nThông qua cấp phát node tự động, sắp xếp workloads thông minh, và vận hành tinh gọn, Cloudera chứng minh cách các tổ chức có thể đạt được hiệu quả trong môi trường container. Theo kiến trúc đã được Cloudera chứng minh, các doanh nghiệp có thể xây dựng một môi trường Kubernetes mạnh mẽ, có khả năng mở rộng và tiết kiệm chi phí, đáp ứng nhu cầu phát triển hiện nay đồng thời chuẩn bị cho sự tăng trưởng trong tương lai. Hãy liên hệ với đội ngũ AWS của bạn để tiến tới xây dựng một môi trường Amazon EKS hiện đại hóa.",
    "description": "Mở rộng môi trường phát triển của Cloudera: Tận dụng Amazon EKS, Karpenter, Bottlerocket và Cilium cho mô hình Hybrid Cloud Harpreet Virk and Padma Iyer | 26/09/2025 | in Advanced (300), Amazon Elastic Kubernetes Service, Best Practices, Containers, Graviton, Migration, Migration Acceleration Program (MAP) | Permalink |\nBài viết này được viết cùng với Shreelola Hegde,Sriharsha Devineni và Lee Watterworth đến từ Cloudera\nCloudera là một công ty hàng đầu thế giới về quản trị dữ liệu doanh nghiệp, phân tích và AI. Nền tảng Cloudera cho phép các tổ chức có thể quản lý, xử lý và phân tích các tập dữ liệu lớn, giúp các doanh nghiệp trong nhiều ngành công nghiệp như tài chính, chăm sóc sức khỏe, sản xuất, và viễn thông đẩy nhanh việc áp dụng AI/ML và mở khóa thông tin chi tiết theo thời gian thực.",
    "tags": [],
    "title": " Blog 4",
    "uri": "/vi/3-blogstranslated/3.4-blog4/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập",
    "content": "Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nSự kiện 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự",
    "description": "Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nSự kiện 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh",
    "tags": [],
    "title": "Các sự kiện đã tham gia",
    "uri": "/vi/4-eventparticipated/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 4: Tìm hiểu về Dịch vụ lưu trữ Amazon S3 Tìm hiểu về Dịch vụ bảo mật trên AWS Thực hiện triển khai được ứng dụng static web thông qua S3 và cloudfront Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xem video bài giảng về dịch vụ lưu trữ S3 - Dịch blogs cho tuần 4 29/9/2025 29/9/2025 https://aws.amazon.com/blogs/migration-and-modernization/scaling-clouderas-development-environment-leveraging-amazon-eks-karpenter-bottlerocket-and-cilium-for-hybrid-cloud/ 3 - Thực hành: + lab57: Khởi Đầu Với Amazon S3 + lab13: Triển khai AWS Backup cho hệ thống + lab 14: VM Import/Export 30/9/2025 30/9/2025 https://000057.awsstudygroup.com https://000014.awsstudygroup.com https://000013.awsstudygroup.com/ 4 - Xem video bài giảng về dịch vụ bảo mật trên AWS 1/10/2025 1/10/2025 5 - Thực hành: + lab2: Quản trị quyền truy cập với AWS Identity and Access Management (IAM) + lab44: IAM Role \u0026 Condition + lab 48: Cấp quyền cho ứng dụng truy cập dịch vụ AWS với IAM Role 2/10/2025 2/10/2025 https://000048.awsstudygroup.com/vi/ https://000002.awsstudygroup.com/vi/ https://000044.awsstudygroup.com/vi/ 6 - Thực hành: + lab30: Giới hạn quyền truy cập với IAM Permission Bounary 3/10/2025 3/10/2025 https://000030.awsstudygroup.com/vi/ Kết quả đạt được tuần 4: Hiểu được về dịch vụ lưu trữ trên S3\nBiết cách triển khai 1 trang web tĩnh thông qua Amazon S3 và cloudFront\nThực hành triển khai backup cho hệ thống\nBiết cách thực hiện import máy chủ ảo từ vm ware vào máy chủ EC2 và ngược lại\nThực hiện quản trị quyền truy cập vào hệ thống với AWS IAM\nTạo IAM Role để thực hiện truy cập dịch vụ AWS mà không dùng AccessKe/Secret Key để đảm bảo an toàn",
    "description": "Mục tiêu tuần 4: Tìm hiểu về Dịch vụ lưu trữ Amazon S3 Tìm hiểu về Dịch vụ bảo mật trên AWS Thực hiện triển khai được ứng dụng static web thông qua S3 và cloudfront Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xem video bài giảng về dịch vụ lưu trữ S3 - Dịch blogs cho tuần 4 29/9/2025 29/9/2025 https://aws.amazon.com/blogs/migration-and-modernization/scaling-clouderas-development-environment-leveraging-amazon-eks-karpenter-bottlerocket-and-cilium-for-hybrid-cloud/ 3 - Thực hành: + lab57: Khởi Đầu Với Amazon S3 + lab13: Triển khai AWS Backup cho hệ thống + lab 14: VM Import/Export 30/9/2025 30/9/2025 https://000057.awsstudygroup.com https://000014.awsstudygroup.com https://000013.awsstudygroup.com/ 4 - Xem video bài giảng về dịch vụ bảo mật trên AWS 1/10/2025 1/10/2025 5 - Thực hành: + lab2: Quản trị quyền truy cập với AWS Identity and Access Management (IAM) + lab44: IAM Role \u0026 Condition + lab 48: Cấp quyền cho ứng dụng truy cập dịch vụ AWS với IAM Role 2/10/2025 2/10/2025 https://000048.awsstudygroup.com/vi/ https://000002.awsstudygroup.com/vi/ https://000044.awsstudygroup.com/vi/ 6 - Thực hành: + lab30: Giới hạn quyền truy cập với IAM Permission Bounary 3/10/2025 3/10/2025 https://000030.awsstudygroup.com/vi/ Kết quả đạt được tuần 4: Hiểu được về dịch vụ lưu trữ trên S3",
    "tags": [],
    "title": "Tuần 4",
    "uri": "/vi/1-worklog/1.4-week4/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Tạo ứng dụng đa vùng với dịch cụ AWS - Phần 1, Tính toán, Mạng và Bảo mật Joe Chapman và Sebastian Leks | 08/12/2021 | Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected | Permalink\nNhiều dịch vụ AWS có các tính năng để giúp bạn xây dựng và quản lý một kiến trúc đa vùng nhưng việc xác định những khả năng đó trên hơn 200 dịch vụ có thể rất khó khăn.\nĐây là chuỗi blog gồm 3 phần, chúng tôi lọc thông qua hơn 200 dịch vụ và tập trung vào những thứ có tính năng cụ thể để hỗ trợ bạn trong việc xây dụng các ứng dụng đa vùng. Trong phần 1, chúng ta sẽ xây dựng một nền tảng với các dịch vụ bảo mật, mạng và tính toán của AWS. Trong phần 2, chúng ta sẽ thêm vào dữ liệu và các chiến lược sao chép. Cuối cùng, trong phần 3, chúng ta sẽ xem xét các lớp ứng dụng và quản lý. Khi chúng ta đi qua từng phần, chúng ta sẽ xây dựng được một ứng dụng ví dụ để minh họa một cách kết hợp các dịch vụ này nhằm tạo ra một ứng dụng đa vùng.\nNhững cân nhắc trước khi bắt đầu AWS Region được xây dựng với nhiều Availbility Zone (AZs) riêng biệt và tách biệt về mặt vật lý. Điều đó cho phép bạn tạo khôi lượng công việc Well-Architected có tính khả dụng cao trải dài trên AZs để đạt được mức khả năng chịu lỗi cao hơn. Điều đó thỏa mãn được các mục tiêu hiện có của hầu hết các ứng dụng, nhưng có một vài lý do khiến bạn có thể nghĩ về việc mở rộng ra ngoài một Region duy nhất:\nMở rộng đến đối tượng toàn cầu khi một ứng dụng phát triển và cơ sở người dùng ngày càng phân tán về mặt địa lý, có thể cần phải giảm độ trễ cho các khu vực khác nhau trên thế giới Giảm Recovery Point Objectives (RPO) and Recovery Time Objectives (RTO) như một phần của kế hoạch phục hồi thảm họa đa khu vực Luật lệ và quy định địa phương có thể có các yêu cầu nghiêm ngặt về quyền riêng tư và lưu trữ dữ liệu phải tuân theo Nếu bạn đang xây dựng một ứng dụng đa vùng mới, bạn có thể muốn xem xét việc tập trung vào những dịch vụ AWS có chức năng tích hợp để hỗ trợ. Các ứng dụng hiện có sẽ cần phải được kiểm tra thêm để xác định kiến trúc có khả năng mở rộng nhất để hỗ trợ sự phát triển của nó. Các phần sau đây sẽ xem xét các dịch vụ này và nêu bật các trường hợp sử dụng cũng như các phương pháp hay nhất.\nXác thực và truy cập khắp các Regions Việc tạo một nền tảng bảo mật bắt đầu với việc cài đặt các luật lệ về xác thực và ủy quyền phù hợp. Hệ thống xử lý các yêu cầu phải có khả năng phục hồi cao để xác minh và cấp phép yêu cầu nhanh chóng và đáng tin cậy. AWS Identity and Access Management (IAM) hoàn thành được việc đó bằng việc tạo một cơ chế đáng tin cậy cho bạn để quản lý truy cập vào tài nguyên và dịch vụ AWS. IAM có sẵn khả dụng ở nhiều vùng một cách tự động, bạn không cần hình gì cả.\nĐể giúp việc quản lý các người dùng , thiết bị, và các ứng dụng Windows trong một mạng đa vùng, bạn có thể thiết lập AWS Directory Service for Microsoft Active Directory phiên bản doanh nghiệp để có thể sao lưu dữ liệu thư mục một cách tự động giữa các Regions. Điều này làm giảm độ trễ tra cứu thư mục bằng cách sử sụng thư mục ở gần nhất và tạo độ bền bằng việc trải dài trên nhiều vùng. Lưu ý rằng điều này cũng sẽ tạo ra cùng một số phận giữa các bộ điều khiển miền trong kiến trúc đa vùng, bởi vì các thay đổi trong group policy sẽ được truyền đến tất cả các máy chủ thành viên.\nCác ứng dụng cần lưu trữ, xoay vòng và kiểm toán thông tin bí mật một cách an toàn, chẳng hạn như mật khẩu cơ sở dữ liệu, nên sử dụng AWS Secrets Manager. Dịch vụ này mã hóa các bí mật với các khóa AWS Key Management Service (AWS KMS) và có thể sao chép bí mật đến vùng thứ hai để đảm bảo các ứng dụng có thể nhanh chóng lấy lại một bí mật tại vùng gần nhất.\nMã hóa trên khắp các khu vực AWS KMS có thể được sử dụng để mã hóa dữ liệu khi lưu trữ và được sử dụng rộng rãi trong các dịch vụ AWS để thực hiện mã hóa. Theo mặc định, các khóa chỉ giới hạn trong một vùng. Các dịch vụ AWS như Amazon Simple Storage Service (Amazon S3) sao chép liên vùng và Amazon Aurora Global Database (cả hai sẽ được đề cập trong phần 2) giúp đơn giản hóa quá trình mã hóa và giải mã với các khóa khác nhau ở từng vùng. Đối với những phần khác của ứng dụng đa vùng phụ thuộc vào khóa KMS, bạn có thể thiết lập AWS KMS multi-Region keys để sao chép vật liệu khóa (key material) và ID khóa sang một vùng khác. Điều này loại bỏ nhu cầu phải giải mã rồi mã hóa lại dữ liệu bằng các khóa khác nhau ở mỗi vùng. Ví dụ: multi-Region keys có thể được sử dụng để giảm độ phức tạp trong các hoạt động mã hóa của ứng dụng đa vùng khi dữ liệu được lưu trữ trên nhiều vùng.\nKiểm toán và khả năng quan sát trên khắp các khu vực Một phương pháp tốt nhất là cấu hình AWS CloudTrail để ghi lại tất cả các hoạt động API liên quan trên tài khoản của bạn phục vụ mục đích kiểm toán. Khi sử dụng nhiều vùng hoặc nhiều tài khoản, các log của CloudTrail nên được tập trung vào một Amazon S3 bucket duy nhất để dễ dàng phân tích. Để tránh việc sử dụng sai mục đích, các log tập trung này nên được xử lý nghiêm ngặt hơn, chỉ cấp quyền truy cập hạn chế cho các hệ thống và nhân sự quan trọng.\nĐể quản lý hiệu quả các kết quả từ AWS Security Hub, bạn có thể tập hợp và liên kết các kết quả từ nhiều vị trí về một vùng (Region) duy nhất. Đây là cách đơn giản để tạo góc nhìn tập trung về các kết quả của Security Hub trên nhiều tài khoản và vùng. Khi thiết lập xong, các kết quả sẽ được đồng bộ liên tục giữa các vùng, giúp bạn cập nhật thông tin toàn cầu ngay trên một bảng điều khiển duy nhất.\nChúng tôi tổng hợp các tính năng này trong Hình 1. Chúng tôi sử dụng IAM để cấp quyền truy cập chi tiết đến các dịch vụ và tài nguyên AWS, Directory Service for Microsoft AD để xác thực người dùng trên các ứng dụng Microsoft, và Secrets Manager để lưu trữ thông tin nhạy cảm như mật khẩu cơ sở dữ liệu. Dữ liệu của chúng tôi, di chuyển tự do giữa các vùng (Regions), được mã hóa bằng KMS multi-Region keys, và tất cả các truy cập API của AWS đều được ghi lại bởi CloudTrail và tập trung vào một S3 bucket trung tâm, chỉ nhóm bảo mật của chúng tôi mới có quyền truy cập.\nHình 1. Multi-Region security, identity, and compliance services\nXây dựng một mạng toàn cầu Với các tài nguyên cần đưa vào mạng ảo trong các vùng khác nhau, Amazon Virtual Cloud (Amazon VPC) cho phép định tuyến riêng biệt giữa các vùng và tài khoản với VPC Peering. Những tài nguyên này có thể giao tiếp bằng cách dùng địa chỉ IP private và không yêu cầu một internet gateway, VPN, hoặc các thiết bị mạng riêng biệt. Tính năng này hoạt động tốt trong các mạng nhỏ vì chỉ yêu cầu một vài kết nối peering. Tuy nhiên, định tuyến chuyển tiếp không cho phép điều đó, và vì số lượng đám mây riêng ảo peering (VPCs) tăng lên, mạng kết nối lưới trở lên khó để quản lý và sửa lỗi.\nAWS Transit Gateway làm giảm các khó khăn bằng cách tạo một hub định tuyến chuyển tiếp để kết nối VPCs và mạng on-premises của bạn. Khả năng định tuyến của Transit Gateway có thể mở rộng sang các Regions khác với Transit Gateway inter-Region peering dể tạo ra mạng lưới riêng tư, phân tán cho các tài nguyên của bạn.\nViệc xây dựng một cách đáng tin cậy, tiết kiệm chi phí để định tuyến các người dùng đến các ứng dụng Internet phân tán yêu cầu Domain Name System (DNS) có khả năng sẵn sàng cao và có thể mở rộng. Amazon Route 53 là dịch vụ có thể đáp ứng yêu cầu này.\nRoute 53 bao gồm nhiều chính sách cho việc định tuyến. Ví dụ, bạn có thể định tuyến một yêu cầu tới một bản ghi có độ trễ mạng thấp nhất, hoặc gửi người dùng ở một vị trí địa lý cụ thể đến điểm cuối ứng dụng gần nhất. Đối với khôi phục sau thảm họa (Disaster Recovery – DR), Route 53 Application Recovery Controller (Route 53 ARC) cung cấp giải pháp chuyển đổi dự phòng toàn diện với ít phụ thuộc nhất. Các chính sách định tuyến, kiểm tra an toàn, và kiểm tra mức sẵn sàng của Route 53 ARC giúp bạn chuyển đổi dự phòng giữa các Region, AZs và on-premises một cách đáng tin cậy.\nAmazon CloundFront, mạng phân phối nội dung toàn cầu (CDN), được xây dựng trên hơn 300 point of presence (PoP) trải rộng trên khắp thế giới. Các ứng dụng có nhiều nguồn gốc dữ liệu, như là giữa các Region, có thể sử dụng CloudFront origin failover để có thể chuyển đổi dự phòng tự động tới origin dự phòng khi cái chính không còn khả dụng. Khả năng của CloudFront không chỉ dừng ở việc phân phối nội dung mà còn có khả năng chạy xử lý ở edge. CloudFront Functions, bạn có thể dễ dàng chạy mã JavaScript nhẹ, và AWS Lambda@Edge, bạn có thể chạy các hàm Node.js và Python gần hơn với người dùng của ứng dụng, giúp cải thiện hiệu năng và giảm độ trễ. Bằng cách đặt xử lý tại edge, bạn giảm tải cho origin và mang lại phản hồi nhanh hơn cho người dùng toàn cầu.\nDựa trên mạng lưới toàn cầu của AWS, AWS Global Accelerator cung cấp hai địa chỉ IP anycast tĩnh để làm điểm vào duy nhất cho các ứng dụng Internet-facing. Bạn có thể thêm hoặc gỡ bỏ origin mà không làm gián đoạn, trong khi hệ thống tự động định tuyến đến endpoint Regional khỏe mạnh gần nhất. Nếu phát hiện sự cố, Global Accelerator sẽ tự động chuyển hướng lưu lượng đến endpoint khả dụng trong vài giây mà không cần thay đổi IP tĩnh.\nHình 2 sử dụng một chính sách định tuyến dựa trên độ trễ của Route53 để định tuyến các người dụng đển endpoint nhanh nhất, CloudFront được sử dụng để phục vụ các nội dung tĩnh như video, hình ảnh và Transit Gateways tạo một mạng riêng toàn cầu để các thiết bị của bạn có thể giao tiếp an toàn giữa các vùng.\nHình 2. AWS VPC connectivity and content delivery\nXây dựng và quản lý lớp tính toán (compute layer) Mặc dù các instance Amazon Elastic Compute Cloud (Amazon EC2) và các volume Amazon Elastic Block Store (Amazon EBS) liên quan chỉ nằm trong một Availability Zone (AZ), Amazon Data Lifecycle Manager có thể tự động hóa quá trình tạo và sao chép snapshot của EBS qua nhiều Region. Điều này giúp nâng cao chiến lược khôi phục sau thảm họa (DR) bằng cách cung cấp một tùy chọn sao lưu “cold” dễ dàng cho các EBS volume. Nếu bạn cần sao lưu nhiều hơn chỉ EBS volume, AWS Backup cung cấp một nơi tập trung để thực hiện việc này trên nhiều dịch vụ, và sẽ được trình bày chi tiết trong phần 2.\nMột instance Amazon EC2 được tạo dựa trên một Amazon Machine Image (AMI). Một AMI xác định cấu hình của instance, chẳng hạn như: lưu trữ, quyền khởi chạy, và ánh xạ thiết bị. Khi cần tạo và phát hành một hình ảnh chuẩn mới, EC2 Image Builder giúp đơn giản hóa việc xây dựng, kiểm thử và triển khai các AMI mới. Nó cũng hỗ trợ sao chép AMI sang các Region khác, không cần phải sao chép thủ công từ Region nguồn sang Region đích.\nCác ứng dụng dựa trên microservices sử dụng container được hưởng lợi từ thời gian khởi động nhanh hơn. Amazon Elastic Container Registry (Amazon ECR) giúp đảm bảo điều này xảy ra nhất quán giữa các Region thông qua sao chép image private ở cấp registry. Một registry private ECR có thể được cấu hình để sao chép giữa các Region hoặc giữa các tài khoản, đảm bảo các image sẵn sàng ở Region phụ khi cần.\nKhi kiến trúc mở rộng ra nhiều Region, việc theo dõi nơi các tài nguyên được cung cấp có thể trở nên khó khăn. Amazon EC2 Global View giúp giảm bớt khó khăn này bằng cách cung cấp một bảng điều khiển tập trung, hiển thị các tài nguyên EC2 như instances, VPC, subnet, security group, và volumes trong tất cả các Region đang hoạt động.\nChúng tôi tổng hợp các tính năng của compute layer trong Hình 3 bằng cách sử dụng EC2 Image Builder để sao chép golden AMI mới nhất của chúng tôi sang các Region khác để triển khai. Chúng tôi cũng sao lưu mỗi EBS volume trong 3 ngày và sao chép chúng qua các Region bằng Data Lifecycle Manager.\nHình 3. AMI and EBS snapshot copy across Regions\nĐưa tất cả lại với nhau Ở cuối mỗi phần của loạt bài blog này, chúng tôi sẽ xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho thấy cách bạn có thể kết hợp các dịch vụ để xây dựng một ứng dụng đa Vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả dịch vụ được nhắc đến, chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến phạm vi toàn cầu. Ứng dụng yêu cầu tính sẵn sàng cao giữa các Vùng, và ưu tiên hiệu năng hơn là tính nhất quán tuyệt đối. Chúng tôi đã chọn các dịch vụ sau (trong bài viết này) để đạt được mục tiêu:\nRoute 53 với chính sách định tuyến theo độ trễ (latency routing) để đưa người dùng đến vùng triển khai có độ trễ thấp nhất.\nCloudFront được thiết lập để phân phối nội dung tĩnh. Region 1 là nguồn gốc chính, nhưng chúng tôi đã cấu hình dự phòng nguồn gốc (origin failover) sang Region 2 trong trường hợp có sự cố.\nỨng dụng phụ thuộc vào một số API của bên thứ ba, vì vậy Secrets Manager với khả năng sao chép đa Vùng đã được thiết lập để lưu trữ thông tin khóa API nhạy cảm.\nCloudTrail logs được tập trung tại Region 1 để dễ dàng phân tích và kiểm toán.\nSecurity Hub tại Region 1 được chọn làm nơi tập hợp các phát hiện từ tất cả các Vùng.\nĐây là ứng dụng dựa trên container, chúng tôi dựa vào Amazon ECR replication tại mỗi vị trí để nhanh chóng tải về các image mới nhất tại chỗ.\nĐể liên lạc qua IP riêng giữa các Vùng, một Transit Gateway được thiết lập tại mỗi Vùng với kết nối liên Vùng. VPC peering cũng có thể hoạt động, nhưng vì dự kiến mở rộng ra nhiều Vùng hơn trong tương lai nên chúng tôi chọn Transit Gateway như giải pháp lâu dài.\nIAM được dùng để cấp quyền quản lý tài nguyên AWS.\nHình 4. Xây dựng ứng dụng với các dịch vụ AWS đa Vùng, sử dụng những dịch vụ đã đề cập trong Phần 1\nTóm tắt Khi thiết kế một ứng dụng đa Vùng (multi-Region), việc xây dựng một nền tảng vững chắc là vô cùng quan trọng. Nền tảng này sẽ giúp bạn phát triển ứng dụng nhanh chóng theo cách an toàn, đáng tin cậy và linh hoạt. Nhiều dịch vụ AWS đã tích hợp sẵn các tính năng hỗ trợ bạn xây dựng kiến trúc đa Vùng.\nTùy vào lý do mở rộng ra ngoài một Vùng duy nhất mà kiến trúc của bạn sẽ khác nhau. Trong bài viết này, chúng tôi đã đề cập đến các tính năng cụ thể của những dịch vụ AWS về bảo mật, mạng và tính toán (compute) — với khả năng tích hợp sẵn để giảm bớt khối lượng công việc nặng nề và lặp lại.\nTrong các bài viết tiếp theo, chúng tôi sẽ tiếp tục đề cập đến các dịch vụ về dữ liệu, ứng dụng và quản lý.\nSẵn sàng để bắt đầu? Chúng tôi đã chọn một số AWS Solutions và AWS Blogs để hỗ trợ bạn!\nBạn đang tìm thêm nội dung về kiến trúc? AWS Architecture Center cung cấp sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được kiểm chứng, những thực tiễn tốt nhất theo Well-Architected, các mẫu (patterns), biểu tượng và nhiều hơn nữa!\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/)",
    "description": "Tạo ứng dụng đa vùng với dịch cụ AWS - Phần 1, Tính toán, Mạng và Bảo mật Joe Chapman và Sebastian Leks | 08/12/2021 | Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected | Permalink\nNhiều dịch vụ AWS có các tính năng để giúp bạn xây dựng và quản lý một kiến trúc đa vùng nhưng việc xác định những khả năng đó trên hơn 200 dịch vụ có thể rất khó khăn.",
    "tags": [],
    "title": " Blog 5",
    "uri": "/vi/3-blogstranslated/3.5-blog5/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 5: Nghiên cứu thêm về Dịch vụ bảo mật trên AWS Thực xong các lab còn lại của module 5 Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Dịch blogs cho tuần 5 06/10/2025 06/10/2025 https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/ 3 - Thực hành: + lab33: Mã hóa ở trạng thái lưu trữ với AWS KMS 07/10/2025 07/10/2025 https://000033.awsstudygroup.com/vi/ 4 - Lập trình api cho dự án cuối khóa module project, section 08/10/2025 08/10/2025 5 - Thực hành: + lab12: Sử dụng AWS IAM Identity Center để quản lý định danh mạnh mẽ 09/10/2025 09/10/2025 https://000012.awsstudygroup.com/vi/ 6 - Lập trình api cho dự án cuối khóa module task 10/10/2025 10/10/2025 Kết quả đạt được tuần 4: Mã hóa dữ liệu trên S3 bằng KMS\nBiết các tạo các group, user, permission set để phần quyền account trên tổ chức\nBiết kết nối tài khoản trong tổ chức trên CLI để sử dụng tài nguyên của dự án\nTạo các permission set theo nhiều cách để quản lý linh hoạt hơn",
    "description": "Mục tiêu tuần 5: Nghiên cứu thêm về Dịch vụ bảo mật trên AWS Thực xong các lab còn lại của module 5 Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Dịch blogs cho tuần 5 06/10/2025 06/10/2025 https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/ 3 - Thực hành: + lab33: Mã hóa ở trạng thái lưu trữ với AWS KMS 07/10/2025 07/10/2025 https://000033.awsstudygroup.com/vi/ 4 - Lập trình api cho dự án cuối khóa module project, section 08/10/2025 08/10/2025 5 - Thực hành: + lab12: Sử dụng AWS IAM Identity Center để quản lý định danh mạnh mẽ 09/10/2025 09/10/2025 https://000012.awsstudygroup.com/vi/ 6 - Lập trình api cho dự án cuối khóa module task 10/10/2025 10/10/2025 Kết quả đạt được tuần 4: Mã hóa dữ liệu trên S3 bằng KMS",
    "tags": [],
    "title": "Tuần 5",
    "uri": "/vi/1-worklog/1.5-week5/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên Jagdish Komakula, Aditya Ambati và Anand Krishna Varanasi | 17/07/2025 | Amazon Elastic Kubernetes Service, Amazon Q, Amazon Q Developer, Developer Tools, Technical How-to | Permalink\nGiới thiệu ArgoCD là một bộ công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernets một cách khai báo, sử dụng Git là nguồn thông tin đáng tin cậy duy nhất. Bộ tính năng mạnh mẽ của nó bao gồm hệ thống đồng bộ tự động, hỗ trợ khôi phục, phát hiện sai lệch, chiến lược triển khai nâng cao, Tích hợp RBAC, và hỗ trợ đa cụm (multi-cluster), khiến nó trở thành giải pháp được ưa chuộng cho việc triển khai ứng dụng trên Kubernetes. Tuy nhiên, khi các tổ chức mở rộng quy mô, một vài điểm khó khăn và thử thách vận hành bắt đầu xuất hiện.\nĐiểm khó khăn khi sử dụng ArgoCD theo phương pháp truyền thống Giao diện của ArgoCD và CLI được thiết kế cho người dùng có nền tảng công nghệ kỹ thuật chuyên sâu. Việc tích hợp tương tác với manifests YAML, hiểu mối quan hệ giữa các tài nguyên Kubernets, và việc khắc phục lỗi đồng bộ đòi hỏi kiến thức chuyên môn cao. Điều này hạn chế khả năng tiếp cập vào quy trình GitOps đối với các bên liên quan ít am hiểu công nghệ và làm tăng sự phụ thuộc vào các kỹ sư DevOps.\nViệc quản lý ArgoCD trên nhiều cụm (clusters) hoặc nhiều môi trường (environments) (sử dụng mô hình hub-spoke, per-cluster, hoặc grouped) tạo ra sự phức tạp đáng kể trong việc vận hành. Các nhóm phải xử lý nhiều instance ArgoCD, duy trì cấu hình nhất quán, và điều phối các triển khai, điều này có thể trở thành một nút thắt khi các quy mô dịch vụ ngày càng mở rộng.\nArgoCD vượt trội trong việc đồng bộ và giám sát các tài nguyên Kubernetes nhưng thiếu cơ chế tích hợp sẵn cho các tác vụ tiền triển khai (ví dụ: quét hình ảnh) và hậu triển khai (ví dụ: việc kiểm tra tải). Điều này khiến các nhóm phải dựa vào các bộ công cụ bên ngoài hoặc các script tùy chỉnh, khiến quy trình triển khai bị phân mảnh và tăng thêm gánh nặng bảo trì.\nViệc chuyển ứng dụng giữa các môi trường (Dev -\u003e Test -\u003e Prod) không được tinh gọn một cách tự nhiên. Các nhóm phải tự mình điều phối thủ công hoặc viết script cho các quy trình chuyển đổi này, việc này làm chậm việc triển khai các bản vá lỗi khẩn cấp và làm phức tạp hóa quá trình phát hành.\nKhi các tổ chức áp dụng các chiến lược đa cụm (multi-cluster), việc quản lý quyền truy cập, RBAC và khả năng hiển thị tài nguyên của ArgoCD trên nhiều môi trường trở nên công kềnh, thường dẫn tới việc làm phân mảnh quy trình làm việc và tạo ra các lỗ hổng bảo mật tiềm ẩn.\nCách ArgoCD MCP Server cùng với Amazon Q CLI giải quyết các vấn đề trên: Việc tích hợp máy chủ ArgoCD MCP với Amazon Q CLI về cơ bản đã thay đổi trải nghiệm người dùng bằng cách giới thiệu tương tác bằng ngôn ngữ tự nhiên cho các thao tác GitOps.\nVới MCP, người dùng có thể quản lý việc triển khai, giám sát trạng thái ứng dụng, và thực hiện thao tác đồng bộ hóa và khôi phục việc vận hành bằng cách sử dụng sử dụng ngôn ngữ giao tiếp thông thường thay vì các câu lệnh kỹ thuật (commands) hoặc YAML. Ví dụ, một người dùng có thể hỏi đơn giản là: “Những ứng dụng nào đang không đồng bộ ở môi trường production?” hay “Đồng bộ ứng dụng api-service,” và hệ thống sẽ thực hiện ngầm các lệnh gọi API ArgoCD phù hợp.\nĐiều này giúp dân chủ hóa quyền truy cập vào GitOps, cho phép các thành viên trong nhóm ít chuyên kỹ thuật (như QA, các người quản lý sản phẩm hoặc kỹ sư hỗ trợ) có thể tương tác an toàn với các quy trình triển khai.\nGiao diện ngôn ngữ tự nhiên giúp loại bỏ độ phức tạp của việc quản lý đa cụm (multi-cluster) và đa môi trường (multi-environment). Người dùng có thể truy vấn hoặc thực hiện hành động trên các tài nguyên giữa các cụm mà không cần ghi nhớ tên tài nguyên, namespace hoặc endpoint API.\nMCP Server xử lý việc xác thực, quản lý session và xử lý lỗi mạnh mẽ, giảm nhu cầu khắc phục sự cố thủ công và viết script tùy chỉnh.\nViệc tích hợp cung cấp các phản hồi chi tiết, xử lý các endpoint thông minh, và các thông báo lỗi toàn diện, giúp cho việc chẩn đoán và giải quyết vấn đề trở nên dễ dàng hơn. Việc kiểm tra kiểu tĩnh hoàn toàn và cấu hình theo môi trường còn nâng cao thêm độ tin cậy và khả năng bảo trì.\nBằng cách tận dụng khả năng mở rộng của Amazon Q CLI, người dùng được tiếp cận với các tích hợp sẵn và gợi ý theo ngữ cảnh, từ đó đẩy nhanh quy trình phát triển và triển khai.\nMCP Server cho phép các trợ lý AI và mô hình ngôn ngữ tự động hóa các tác vụ định kỳ, đề xuất hành động và thậm chí gỡ lỗi (debug) các vấn đề, hoạt động như một kỹ sư DevOps ảo. Điều này có thể giảm đáng kể công sức thủ công và tăng tốc độ phản hồi sự cố.\nSo sánh ArgoCD truyền thống với ArgoCD MCP Server và Amazon Q CLI Tính năng/Thách thức ArgoCD truyền thống MPC Server + Amazon Q CLI Giao diện người dùng Giao diện kỹ thuật (UI/CLI), yêu cầu thao tác với YAML Ngôn ngữ tự nhiên, tương tác hội thoại Khả năng truy cập cho người không phải kỹ sư Hạn chế Mở rộng, dân chủ hóa Quản lý đa cụm Phức tạp, thủ công Đơn giản hóa, được trừu tượng hóa Tác vụ Tiền/Hậu Triển khai Cần công cụ bên ngoài/script Vẫn dùng công cụ bên ngoài, nhưng dễ gọi hơn Chuyển đổi ứng dụng Thủ công hoặc dùng script Ngôn ngữ tự nhiên, điều phối dễ dàng hơn Khắc phục sự cố Mang tính kỹ thuật, dễ xảy ra lỗi Được hướng dẫn, có hỗ trợ AI, phản hồi chi tiết Tự động hóa Yêu cầu viết script Do AI/agent điều khiển, chủ động Bạn có thể thực hiện các thao tác sau bằng ngôn ngữ tự nhiên nhờ tích hợp Amazon Q CLI với ArgoCD MCP server:\nQuản lý ứng dụng: Liệt kê, khởi tạo, cập nhật và xóa các ứng dụng ArgoCD.\nThao tác đồng bộ: Kích hoạt đồng bộ và theo dõi trạng thái\nTrực quan hóa cây tài nguyên: Xem cấu trúc phân cấp của các tài nguyên do ứng dụng quản lý\nGiám sát trạng thái sức khỏe: Kiểm tra trạng thái sức khỏe của các ứng dụng và các tài nguyên của chúng.\nTheo dõi sự kiện: Xem các sự kiện liên quan đến ứng dụng và tài nguyên.\nTruy cập log: Truy xuất log từ các workload của ứng dụng.\nThực hiện hành động trên tài nguyên: Gọi các thao tác trên tài nguyên được quản lý bởi ứng dụng\nThiết lập môi trường của bạn Các điều kiện tiên quyết Sau đây là các điều kiện tiên quyết cho việc thiết lập môi trường EKS của bạn, sau đó sẽ được quản lý bởi ArgoCD thông qua Amazon CLI.\nMột tài khoản AWS với quyền thích hợp\nAWS CLI phiên bản 2.13.0 hoặc mới hơn\nNode.js phiên bản 18.0.0 hoặc mới hơn\nnpm phiên bản 9.0.0 hoặc mới hơn\nAmazon Q CLI phiên bản 1.0.0 hoặc mới hơn (npm install -g @aws/amazon-q-cli)\nMột cụm EKS (phiên bản 1.27 hoặc mới hơn) đã được cài ArgoCD phiên bản 2.8 hoặc mới hơn\nKết nối với cụm EKS của bạn Sử dụng AWS CLI để cập nhật kubeconfig của bạn aws eks update-kubeconfig --name \u003ccluster_name\u003e --region \u003cregion\u003e --role-arn \u003ciam_role_arn\u003e\nXác minh các pod ArgoCD đang chạy đúng cách trong namespace argocd kubectl get pods -n argocd\nTruy cập giao diện người dùng ArgoCD server trên máy cục bộ bằng lệnh chuyển tiếp port kubectl port-forward svc/blueprints-addon-argocd-server -n argocd 8080:443\nTạo ArgoCD API token Truy cập vào ArgoCD UI tại https://localhost:8080 Đăng nhập bằng thông tin đăng nhập của tài khoản admin Điều hướng đến User Settings \u003e API Tokens Nhấp vào “Generate New” để tạo một token mới Tạo một tệp cấu hình Amazon Q CLI MCP tại đường dẫn .amazonq/mcp.json và cập nhật các giá trị ARGOCD_BASE_URL và ARGOCD_API_TOKEN sao cho phù hợp với thiết lập môi trường của bạn. Tích hợp với Amazon Q CLI { \"mcpServers\": { \"argocd-mcp-stdio\": { \"type\": \"stdio\", \"command\": \"npx\", \"args\": [ \"argocd-mcp@latest\", \"stdio\" ], \"env\": { \"ARGOCD_BASE_URL\": \"\u003cARGOCD_BASE_URL\u003e\", \"ARGOCD_API_TOKEN\": \"\u003cARGOCD_API_TOKEN\u003e\", \"NODE_TLS_REJECT_UNAUTHORIZED\": \"0\" } } } }\rKhi cấu hình xong, bạn có thể bắt đầu sử dụng câu lệnh bằng ngôn ngữ tự nhiên với Amazon Q CLI để tương tác với các ứng dụng ArgoCD của mình.\nQuản lý các ứng dụng bằng cách sử dụng ngôn ngữ tự nhiên Dưới đây là một số câu lệnh (prompts) để tương tác với các ứng dụng ArgoCD trong cụm EKS của bạn\nLiệt kê ứng dụng Argo\nCâu lệnh: List all ArgoCD applications in my cluster\nAmazon Q sẽ sử dụng máy chủ ArgoCD MCP để truy xuất và hiển thị tất cả các ứng dụng\nTạo ứng dụng ArgoCD mới\nCâu lệnh: Create new argocd application using App name: game-2048 Repo: https://github.com/aws-ia/terraform-aws-eks-blueprints Path: patterns/gitops/getting-started-argocd/k8s. Branch: main Namespace: argocd\nAmazon Q sẽ tạo một ứng dụng mới từ thông tin GitRepo cung cấp\nXem trạng thái triển khai\nCâu lệnh: Show me the resource tree for team-carmen app\nAmazon Q sẽ hiển thị cấu trúc phân cấp của các tài nguyên Kubernetes do ứng dụng quản lý.\nĐồng bộ hóa ứng dụng\nCâu lệnh: Show me the applications that’s out of sync\nAmazon Q sẽ hiển thị các ứng dụng không đồng bộ\nCâu lệnh: Sync the application\nAmazon Q đang đồng bộ hóa các ứng dụng\nAmazon Q sẽ:\nKhởi tạo hoạt động đồng bộ cho ứng dụng đã chỉ định Giám sát quá trình động bộ hóa Báo trạng thái cuối cùng của hoạt động đồng bộ hóa Kiểm tra sức khỏe và giám sát\nCâu lệnh: Check the health of all resources in the team-geordie application\nAmazon Q đang đưa ra trạng thái sức khỏe của tất cả tài nguyên trong một ứng dụng\nAmazon Q sẽ:\nTruy vấn trạng thái sức khỏe của tất cả tài nguyên Xác định bất cứ thành phần nào không lành mạnh Cung cấp các khuyến nghị để giải quyết các vấn đề Câu lệnh: Show me the logs for the failing pod in the team-platform application\nAmazon Q đang hiển thị các log của pod gặp sự cố\nAmazon Q sẽ:\nXác định các pod gặp sự cố Truy vấn và hiển thị các log có liên quan Làm nổi bật các thông báo lỗi tiềm ẩn Tổng kết Việc tích hợp Amazon Q CLI với ArgoCD thông qua MCP server đánh dấu một bước tiến mang tính chuyển đổi trong việc quản lý Kubernets, kết hợp khả năng GitOps của ArgoCD với công nghệ xử lý ngôn ngữ tự nhiên của Amazon Q. Bằng cách chuyển đổi các thao tác phức tạp trên Kubernets thành các tương tác hội thoại đơn giản, giải pháp này cho phép các nhóm có thể tập trung vào điều thực sự quan trọng - tạo ra giá trị cho doanh nghiệp. Hơn là dành thời gian ghi nhớ các lệnh hoặc vật lộn với những kỹ thuật phức tạp, giờ đây các nhóm có thể quản lý hạ tầng cloud của họ thông qua đối thoại tự nhiên, giúp hành trình cloud-native trở nên dễ tiếp cận và hiệu quả hơn cho mọi người. Sẵn sàng cho việc chuyển đổi trải nghiệm EKS và ArgoCD của bạn chưa? Hãy thử tích hợp Amazon Q CLI với ArgoCD MCP ngay và khám phá lý do vì sao các đội DevOps đang đưa nó vào bộ công cụ thiết yếu của họ.",
    "description": "Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên Jagdish Komakula, Aditya Ambati và Anand Krishna Varanasi | 17/07/2025 | Amazon Elastic Kubernetes Service, Amazon Q, Amazon Q Developer, Developer Tools, Technical How-to | Permalink\nGiới thiệu ArgoCD là một bộ công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernets một cách khai báo, sử dụng Git là nguồn thông tin đáng tin cậy duy nhất. Bộ tính năng mạnh mẽ của nó bao gồm hệ thống đồng bộ tự động, hỗ trợ khôi phục, phát hiện sai lệch, chiến lược triển khai nâng cao, Tích hợp RBAC, và hỗ trợ đa cụm (multi-cluster), khiến nó trở thành giải pháp được ưa chuộng cho việc triển khai ứng dụng trên Kubernetes. Tuy nhiên, khi các tổ chức mở rộng quy mô, một vài điểm khó khăn và thử thách vận hành bắt đầu xuất hiện.",
    "tags": [],
    "title": " Blog 6",
    "uri": "/vi/3-blogstranslated/3.6-blog6/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 6: Học về dịch vụ cơ sở dữ liệu trên cloud của AWS Thực hành các bài lab liên quan tới việc sử dụng RDS Ôn tập lại nội dung và bài thực hành của module 2 về VPC Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập xem lại module 2: Tìm hiểu kiến trúc VPC cơ bản và các thành phần quan trọng có liên quan 12/10/2025 12/10/2025 3 - Học module : Dịch vụ lưu trữ cơ sở dữ liệu trên AWS 13/10/2025 13/10/2025 Chuỗi video về module trên kênh AWS Study Group 4 - Thực hành: lab 05: Amazon Relational Database Service (Amazon RDS) 14/10/2025 14/10/2025 https://000005.awsstudygroup.com/vi/ 5 - Học sử dụng bộ nhớ cache, Redis cho đồ án cuối khóa 15/10/2025 15/10/2025 https://www.youtube.com/watch?v=HSknuSIoK6A 6 - Thực hành: lab 03: Bắt đầu với Amazon Virtual Private Cloud (VPC) và AWS Site-to-Site VPN 16/10/2025 16/10/2025 https://000003.awsstudygroup.com/vi/ Kết quả đạt được tuần 6: Học về các loại dịch vụ cơ sở dữ liệu: RDS, Elastic Cache, Red Shift\nHiểu về database concept và các thuật ngữ cần quan tâm khi thực hiện thao tác với cơ sở dữ liệu\nThực hành bài lab để triển khai hệ thống có sử dụng RDS để lưu trữ thông tin, kiểm tra log của cơ sở dữ liệu\nThực hành lại bài lab triển khai VPC để thành thục hơn khi triển khai VPC và sửa các lỗi khi triển khai\nHọc được cách cache dữ liệu lên Redis và các bảo vệ hệ thống tránh bị spam, bị mất dữ liệu",
    "description": "Mục tiêu tuần 6: Học về dịch vụ cơ sở dữ liệu trên cloud của AWS Thực hành các bài lab liên quan tới việc sử dụng RDS Ôn tập lại nội dung và bài thực hành của module 2 về VPC Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập xem lại module 2: Tìm hiểu kiến trúc VPC cơ bản và các thành phần quan trọng có liên quan 12/10/2025 12/10/2025 3 - Học module : Dịch vụ lưu trữ cơ sở dữ liệu trên AWS 13/10/2025 13/10/2025 Chuỗi video về module trên kênh AWS Study Group 4 - Thực hành: lab 05: Amazon Relational Database Service (Amazon RDS) 14/10/2025 14/10/2025 https://000005.awsstudygroup.com/vi/ 5 - Học sử dụng bộ nhớ cache, Redis cho đồ án cuối khóa 15/10/2025 15/10/2025 https://www.youtube.com/watch?v=HSknuSIoK6A 6 - Thực hành: lab 03: Bắt đầu với Amazon Virtual Private Cloud (VPC) và AWS Site-to-Site VPN 16/10/2025 16/10/2025 https://000003.awsstudygroup.com/vi/ Kết quả đạt được tuần 6: Học về các loại dịch vụ cơ sở dữ liệu: RDS, Elastic Cache, Red Shift",
    "tags": [],
    "title": "Tuần 6",
    "uri": "/vi/1-worklog/1.6-week6/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa Ryan Coleman và Belle Guttman | 15/07/2025 | Amazon Machine Learning, Announcements, Artificial Intelligence, Open Source| Permalink | Comments\nHôm nay, chúng tôi vui mừng thông báo về phiên bản 1.0 của Strands Agents SDK, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho môi trường production. Strands Agents là một SDK mã nguồn mở, áp dụng phương pháp model-driven, giúp bạn xây dựng và vận hành các agent AI chỉ trong vài dòng code. Strands có khả năng mở rộng từ các trường hợp sử dụng agent đơn giản đến phức tạp, cũng như từ phát triển cục bộ đến triển khai trong môi trường production.\nKể từ khi ra mắt bản xem trước vào tháng 5 năm 2025, chúng tôi đã nhận được hơn 2.000 lượt sao trên GitHub và hơn 150 ngàn lượt tải xuống trên PyPI. Strands 1.0 mang đến mức độ đơn giản tương tự cho các ứng dụng multi-agent như những gì Strands đã làm được với các agent đơn lẻ, với việc bổ sung bốn primitive mới và hỗ trợ cho giao thức Agent to Agent (A2A). Để đưa kiến trúc multi-agent vào môi trường production, phiên bản 1.0 cũng bao gồm một trình quản lý session mới để truy xuất trạng thái agent từ một kho dữ liệu từ xa, cùng với việc cải thiện hỗ trợ bất đồng bộ xuyên suốt toàn bộ SDK. Nhằm tăng tính linh hoạt để xây dựng agent của bạn với bất kỳ mô hình nào, cStrands 1.0 đã mở rộng hỗ trợ thêm API của năm nhà cung cấp mô hình mới, được đóng góp bởi các đối tác như Anthropic, Meta, OpenAI, Cohere, Mistral, Stability, Writer và Baseten (xem pull request). Bây giờ, hãy cùng đi sâu vào chi tiết các cập nhật này. Các mẫu code đầy đủ có sẵn tại trang strandsagents.com.\nĐơn giản hóa các mô hình multi-agent Các mô hình multi-agent cho phép các agent AI chuyên biệt cùng nhau làm việc—phân công nhiệm vụ, chia sẻ kiến thức và phối hợp hành động—nhằm giải quyết những vấn đề phức tạp mà một agent đơn lẻ không thể xử lý được. Strands 1.0 giới thiệu bốn primitive trực quan, giúp việc điều phối nhiều agent trở thành một phần mở rộng đơn giản của tổ hợp mô hình/công cụ/prompt mà bạn vốn đã sử dụng để tạo ra các agent đơn lẻ.\n1. Agents-as-Tools: Đơn giản hóa việc ủy quyền theo cấp bậc\nMô hình agents-as-tools biến các agent chuyên biệt thành những công cụ thông minh mà các agent khác có thể gọi đến. Điều này tạo điều kiện cho việc ủy quyền theo cấp bậc, nơi các agent hoạt động như người điều phối có thể chủ động tham vấn các chuyên gia theo từng lĩnh vực cụ thể mà không từ bỏ quyền kiểm soát yêu cầu. Điều này phản ánh cách thức làm việc của các đội nhóm con người — một quản lý dự án không cần phải biết mọi thứ, họ chỉ cần biết nên tham khảo ý kiến của chuyên gia nào cho từng nhiệm vụ cụ thể.\nfrom strands import Agent, tool from strands_tools import calculator, file_write, python_repl, journal @tool def web_search(query: str) -\u003e str: return \"Dummy web search results here!\" # Create specialized agents research_analyst_agent = Agent( system_prompt=\"You are a research specialist who gathers and analyzes information about local startup markets\", tools=[web_search, calculator, file_write, python_repl] ) travel_advisor_agent = Agent( system_prompt=\"You are a travel expert who helps with trip planning and destination advice\", tools=[web_search, journal] ) # Convert the agents into tools @tool def research_analyst(query: str) -\u003e str: response = research_analyst_agent(query) return str(response) @tool def travel_advisor(query: str) -\u003e str: response = travel_advisor_agent(query) return str(response) # Orchestrator naturally delegates to specialists executive_assistant = Agent( tools=[research_analyst, travel_advisor] ) result = executive_assistant(\"I have a business meeting in Portland next week. Suggest a nice place to stay near the local startup scene, and suggest a few startups to visit\") Trong ví dụ rút gọn này, chúng ta định nghĩa hai agent du lịch và nghiên cứu, mỗi agent có prompt và công cụ chuyên biệt cho lĩnh vực của mình, mà agent trợ lý điều hành có thể gọi đến để lấy thông tin phục vụ yêu cầu của người dùng. agent trợ lý điều hành chịu trách nhiệm tổng hợp đầu vào từ các agent khác và tạo ra phản hồi gửi lại cho người dùng. Tìm hiểu thêm về mô hình Agents-as-Tools trong tài liệu chính thức của Strands.\n2. Handoffs: chuyển giao quyền kiểm soát rõ ràng\nTính năng Handoffs cho phép các agent chủ động chuyển trách nhiệm sang con người khi gặp phải nhiệm vụ vượt quá phạm vi chuyên môn của mình, đồng thời giữ nguyên toàn bộ ngữ cảnh cuộc trò chuyện trong quá trình chuyển giao. Strands cung cấp sẵn công cụ được tích hợp sẵn handoff_to_user giúp cho các agent có thể dùng để chuyển giao quyền kiểm soát một cách liền mạch trong khi vẫn duy trì lịch sử và ngữ cảnh cuộc trò chuyện - giống như một nhân viên dịch vụ khách hàng cung cấp chủ động yêu cầu khách cung cấp thêm thông tin về trường hợp của họ.\nfrom strands import Agent from strands_tools import handoff_to_user SYSTEM_PROMPT=\"\"\" Answer the user's support query. Ask them questions with the handoff_to_user tool when you need more information \"\"\" # Include the handoff_to_user tool in our agent's tool list agent = Agent( system_prompt=SYSTEM_PROMPT, tools=[handoff_to_user] ) # The agent calls the handoff_to_user tool which includes the question for the customer agent(\"I have a question about my order.\")\rCác agent cũng có thể đặt câu hỏi cho con người khi được yêu cầu làm như vậy\nfrom strands import Agent SYSTEM_PROMPT=\"\"\" Answer the user's support query. Ask them questions when you need more information \"\"\" agent = Agent( system_prompt=SYSTEM_PROMPT, ) # The agent asks questions by streaming them back as text agent(\"I have a question about my order.\")\r3. Swarms: Các nhóm cộng tác tự tổ chức\nMột Swarm tạo ra các agent tự chủ phối hợp động thông qua việc chia sẻ bộ nhớ,cho phép nhiều chuyên gia có thể cộng tác cho các tác vụ phức tạp. Hãy hình dung nó giống như một buổi thảo luận nhóm, nơi các chuyên gia xây dựng ý tưởng dựa trên ý tưởng của nhau, với đội ngũ tự tổ chức để mang lại kết quả tập thể tốt nhất.\nimport logging from strands import Agent from strands.multiagent import Swarm from strands_tools import memory, calculator, file_write # Enables Strands debug logs level, and prints to stderr logging.getLogger(\"strands.multiagent\").setLevel(logging.DEBUG) logging.basicConfig( format=\"%(levelname)s | %(name)s | %(message)s\", handlers=[logging.StreamHandler()] ) researcher = Agent( name=\"researcher\", system_prompt=\"You research topics thoroughly using your memory and built-in knowledge\", tools=[memory] ) analyst = Agent( name=\"analyst\", system_prompt=\"You analyze data and create insights\", tools=[calculator, memory] ) writer = Agent( name=\"writer\", system_prompt=\"You write comprehensive reports based on research and analysis\", tools=[file_write, memory] ) # Swarm automatically coordinates agents market_research_team = Swarm([researcher, analyst, writer]) result = market_research_team( \"What is the history of AI since 1950? Create a comprehensive report\" ) Nghiên cứu thêm về Swarms trong tài liệu về Strands\n4. Graphs: Kiểm soát quy trình làm việc mang tính xác định\nGraphs cho phép bạn xác định quy trình làm việc của các agent một cách rõ ràng với những định tuyến có điều kiện và những điểm ra quyết định, rất hữu ích cho những quy trình yêu cầu các bước cụ thể, cơ chế phê duyệt hoặc các ngưỡng kiểm soát chất lượng. Giống như một dây chuyền lắp ráp hoặc chuỗi phê duyệt được thiết kế tốt, graphs đảm bảo các agent luôn tuân thủ các quy tắc nghiệp vụ đã định sẵn theo đúng trình tự mỗi lần thực thi.\nfrom strands import Agent from strands.multiagent import GraphBuilder analyzer_agent = Agent( name=\"analyzer\", system_prompt=\"Analyze customer requests and categorize them\", tools=[text_classifier, sentiment_analyzer] ) normal_processor = Agent( name=\"normal_processor\", system_prompt=\"Handle routine requests automatically\", tools=[knowledge_base, auto_responder] ) critical_processor = Agent( name=\"critical_processor\", system_prompt=\"Handle critical requests quickly\", tools=[knowledge_base, escalate_to_support_agent] ) # Build deterministic workflow builder = GraphBuilder() builder.add_node(analyzer_agent, \"analyze\") builder.add_node(normal_processor, \"normal_processor\") builder.add_node(critical_processor, \"critical_processor\") # Define conditional routing def is_approved(state): return True def is_critical(state): return False builder.add_edge(\"analyze\", \"normal_processor\", condition=is_approved) builder.add_edge(\"analyze\", \"critical_processor\", condition=is_critical) builder.set_entry_point(\"analyze\") customer_support_graph = builder.build() # Execute the graph with user input results = customer_support_graph(\"I need help with my order!\") Nghiên cứu thêm về Graphs trong tài liệu về Strands\nCác mô hình multi-agent (multi-agent patterns) này được thiết kế để được áp dụng dần dần và kết hợp một cách tự do — hãy bắt đầu với các agent đơn lẻ, thêm các chuyên gia như là công cụ, phát triển thành các Swarms, và điều phối bằng các Graphs khi nhu cầu của bạn tăng lên. Hãy kết hợp và tùy chỉnh các mô hình để tạo ra các hệ thống tinh vi: swarms có thể chứa các graphs, graphs có thể điều phối các swarms, và bất kỳ mô hình nào cũng có thể sử dụng các agent được trang bị thêm các agent khác làm công cụ.\nfrom strands import Agent, tool from strands.multiagent import GraphBuilder, Swarm from strands_tools import memory, calculator, python_repl, file_write # Start simple with a single agent agent = Agent(tools=[memory]) # Create specialist agents that a lead orchestrator agent can consult data_analyst = Agent(name=\"analyst\", tools=[calculator, python_repl]) @tool def data_analyst_tool(query: str) -\u003e str: return str(data_analyst(query)) analyst_orchestrator = Agent(tools=[memory, data_analyst_tool]) # Agents-as-tools # Compose patterns together - a graph that uses a swarm researcher = Agent(name=\"researcher\", tools=[memory]) writer = Agent(name=\"writer\", tools=[file_write]) research_swarm = Swarm([researcher, analyst_orchestrator, writer]) review_agent = Agent(system_prompt=\"Review the research quality and suggest improvements\") builder = GraphBuilder() builder.add_node(research_swarm, \"research\") # Swarm as graph node builder.add_node(review_agent, \"review\") builder.add_edge(\"research\", \"review\") graph = builder.build() # The patterns nest naturally - swarms in graphs, agents as tools everywhere result = graph(\"How has green energy evolved over the last few years?\") Hệ thống Multi-Agent với A2A Strand 1.0 đã bao gồm việc hỗ trợ cho giao thức Agent-to-Agent (A2A), một tiêu chuẩn mở cho phép các agent từ các nền tảng khác nhau có thể giao tiếp một cách liền mạch. Bất kỳ agent Strands cũng có thể được tích hợp các khả năng A2A để trở nên có thể truy cập qua mạng và tuân thủ giao thức A2A. Các agent A2A từ các tổ chức bên ngoài cũng có thể được sử dụng trực tiếp trong tất cả các mô hình multi-agent của Strands.\nfrom strands import Agent from strands.multiagent.a2a import A2AServer from strands_tools.a2a_client import A2AClientToolProvider # Serve your agent via A2A protocol local_agent = Agent(name=\"analyzer\", tools=[web_search, data_analysis]) a2a_agent = A2AServer(agent=local_agent, port=9000) a2a_agent.serve() # AgentCard available at http://localhost:9000/.well-known/agent.json # Use remote A2A agents partner_agent_url = \"https://partner.com\" cloud_agent_url = \"https://cloud.ai\" # Connect to remote A2A enabled agents a2a_tool_provider = A2AClientToolProvider(known_agent_urls=[partner_agent_url, cloud_agent_url]) # Orchestrate remote agents orchestrator = Agent(tools=[a2a_tool_provider.tools]) Bởi vì A2A cung cấp các tính năng như agent card, một mô tả được chuẩn hóa về khả năng của agent, các hệ thống multi-agent được bật A2A có thể dễ dàng khám phá và kết nối với các agent được tạo ra bởi các nhóm hoặc các tổ chức khác. Strands tự động tạo ra thẻ agent dựa trên các công cụ bạn đã cung cấp cho agent. Để xem các ví dụ hoạt động hoàn chỉnh và bắt đầu với tính năng tích hợp A2A, hãy tham khảo repository mẫu của chúng tôi và tài liệu A2A của Strands.\nSẵn sàng cho môi trường production Mặc dù Strands đã được các đội nội bộ của Amazon như Amazon Q Developer và AWS Glue sử dụng trong môi trường production từ lâu trước khi ra mắt công chúng, chúng tôi đã và đang làm việc ngược lại với hàng trăm khách hàng trên toàn thế giới để mở rộng Strands nhằm đáp ứng các nhu cầu production của bạn. Các cập nhật này bao gồm một tầng trừu tượng quản lý session để hỗ trợ việc lưu trữ liên tục dữ liệu vào và phục hồi từ các kho dữ liệu bên ngoài, đầu ra có cấu trúc, cải thiện hỗ trợ bất đồng bộ, và nhiều thứ khác nữa (xem chi tiết trong changelog các phiên bản phát hành)\nQuản lý session bền vững: Chúng tôi đã thêm vào SessionManager, một công cụ trừu tượng hóa quản lý session cho phép tự động lưu trữ liên tục và khôi phục lịch sử hội thoại cũng như trạng thái của agent. Nhờ đó, các agent có thể lưu toàn bộ lịch sử cuộc trò chuyện vào một hệ thống lưu trữ như Amazon Simple Storage Service (Amazon S3) và tiếp tục cuộc hội thoại một cách liền mạch ngay cả sau khi hệ thống khởi động lại. Dưới đây là một ví dụ sử dụng cơ chế lưu trữ liên tục dựa trên file cơ bản.\nfrom strands import Agent from strands.session.file_session_manager import FileSessionManager # Create a session manager with file-based storage Session_manager = FileSessionManager(session_id=”customer_support”, base_dir=\"./agent_sessions\") # Agent automatically persists all conversations agent = Agent( id=\"support_bot_1\", session_manager=session_manager, tools=[knowledge_base, ticket_system] ) # Messages are automatically saved as the conversation progresses agent(\"Help me reset my password\") agent(\"I can't access my email\") # Later, even after a restart, restore the full conversation Bạn có thể mở rộng lớp trừu tượng này bằng cách tự triển khai backend lưu trữ của riêng mình thông qua mẫu thiết kế Data Access Object (DAO), và Strands đã tích hợp sẵn hai backend mặc định: hệ thống file cục bộ và Amazon S3. Mỗi agent nhận một ID duy nhất để theo dõi, và hệ thống xử lý các agent đồng thời trong cùng một session cho các kịch bản multi-agent, đảm bảo rằng các agent luôn duy trì ngữ cảnh qua các lần triển khai, mở rộng quy mô hệ thống hoặc khởi động lại. Tìm hiểu thêm về Session Management trong tài liệu của Strands.\nHỗ trợ bất đồng bộ nguyên bản và cải thiện hiệu năng: Các workload trong môi trường production đòi hỏi độ tin cậy cao và hiệu năng phản hồi nhanh. Trong phiên bản 1.0, chúng tôi đã cải tiến kiến trúc vòng lặp sự kiện của Strands để hỗ trợ thao tác bất đồng bộ trên toàn bộ stack. Các công cụ và nhà cung cấp mô hình giờ đây có thể chạy bất đồng bộ mà không bị chặn, cho phép thực thi đồng thời thực sự. Phương thức stream_async mới truyền phát tất cả các sự kiện của agent — văn bản, việc sử dụng công cụ, các bước suy luận — theo thời gian thực, vđồng thời tích hợp cơ chế hủy khi người dùng rời khỏi trang.\nimport asyncio from fastapi import FastAPI from fastapi.responses import StreamingResponse from strands import Agent from strands_tools import calculator app = FastAPI() @app.post(\"/chat\") async def chat_endpoint(message: str): async def stream_response(): agent = Agent(tools=[web_search, calculator]) # Stream agent responses in real-time async for event in agent.stream_async(message): if \"data\" in event: yield f\"data: {event['data']}\\n\\n\" elif \"current_tool_use\" in event: yield f\"event: tool\\ndata: Using {event['current_tool_use']['name']}\\n\\n\" return StreamingResponse(stream_response(), media_type=\"text/event-stream\") # Concurrent agent evaluation async def evaluate_models_concurrently(prompt: str): async def stream(agent: Agent): print(f\"STARTING: {agent.name}\") async for event in agent.stream_async(prompt): # handle events print(f\"ENDING: {agent.name}\") return event[“result”] # last event is the agent result agents = [ Agent(name=\"claude\", model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0”), Agent(name=\"deepseek”, model=\"us.deepseek.r1-v1:0”), Agent(name=\"nova\", model=\"us.amazon.nova-pro-v1:0\") ] # Execute all agents concurrently responses = await asyncio.gather(*[stream(agent) for agent in agents]) return responses Tìm hiểu thêm về Hỗ trợ bất động bộ nguyên bản trong tài liệu chính thức của Strands.\nMở rộng hỗ trợ đa dạng nhà cung cấp mô hình: Khách hàng đã chia sẻ rằng họ cần linh hoạt trong việc sử dụng các mô hình khác nhau cho các tác vụ khác nhau. Để đáp ứng nhu cầu này, Strands Agents đã nhận được sự hỗ trợ mạnh mẽ từ cộng đồng các nhà cung cấp mô hình. Các nhà cung cấp như Anthropic, Meta, OpenAI, Cohere, Mistral, Stability và Writer đã đóng góp cho phép API mô hình của họ được sử dụng bởi một Strands Agent thông qua code. Việc truy cập Strands Agents thông qua hạ tầng API do chính các nhà cung cấp này cung cấp giúp các nhà phát triển tập trung vào việc xây dựng các giải pháp AI-powered, mà không cần lo lắng về quản lý cơ sở hạ tầng. Những bổ sung này bổ trợ hoàn hảo cho khả năng hỗ trợ từ giai đoạn xem trước đối với mọi mô hình trên Amazon Bedrock, OpenAI, và bất kỳ endpoint tương thích OpenAI nào thông qua LiteLLM. Strands cho phép bạn sử dụng các mô hình khác nhau cho mỗi agent, hoặc chuyển đổi mô hình và nhà cung cấp mô hình mà không cần sửa đổi công cụ hoặc logic của bạn.\nfrom strands import Agent from strands.models import BedrockModel from strands.models.openai import OpenAIModel from strands.models.anthropic import AnthropicModel # Configure different model providers bedrock_model = BedrockModel( model_id=\"us.amazon.nova-pro-v1:0\", temperature=0.3, top_p=0.8, region_name=\"us-west-2\" ) openai_model = OpenAIModel( client_args={ \"api_key\": \"your-api-key\", }, model_id=\"gpt-4o\", params={ \"max_tokens\": 1000, \"temperature\": 0.7, } ) anthropic_model = AnthropicModel( client_args={ \"api_key\": \"your-api-key\", }, max_tokens=1028, model_id=\"claude-3-7-sonnet-20250219\", params={ \"temperature\": 0.5, } ) # Swap models or use different models for different agents in the same system researcher = Agent( name=\"researcher\", model=anthropic_model, tools=[web_search] ) writer = Agent( name=\"writer\", model=openai_model, tools=[document_formatter] ) analyzer = Agent( name=\"analyzer\", model=bedrock_model, tools=[data_processor] )\rCộng đồng Strands đã đóng vai trò then chốt trong việc định hình tất cả những cải tiến này thông qua việc sử dụng thực tế, phản hồi và những đóng góp mã nguồn trực tiếp. Trong số hơn 150 pull request (PR) đã được merge vào Strands từ phiên bản 0.1.0 đến 1.0, 22% được đóng góp bởi các thành viên cộng đồng, những người đã sửa lỗi, thêm nhà cung cấp mô hình, viết tài liệu, thêm tính năng và tái cấu trúc các lớp để cải thiện hiệu suất. Chúng tôi vô cùng biết ơn mỗi người trong số các bạn vì đã giúp Strands trở thành cách đơn giản nhất để đưa một agent từ nguyên mẫu đến triển khai thực tế.\nTương lai của AI là multi-agent (multi-agent), và với Strands 1.0, tương lai đó đã sẵn sàng để triển khai trong môi trường production. Hãy bắt đầu xây dựng ngay hôm nay tại strandsagents.com.",
    "description": "Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa Ryan Coleman và Belle Guttman | 15/07/2025 | Amazon Machine Learning, Announcements, Artificial Intelligence, Open Source| Permalink | Comments\nHôm nay, chúng tôi vui mừng thông báo về phiên bản 1.0 của Strands Agents SDK, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho môi trường production. Strands Agents là một SDK mã nguồn mở, áp dụng phương pháp model-driven, giúp bạn xây dựng và vận hành các agent AI chỉ trong vài dòng code. Strands có khả năng mở rộng từ các trường hợp sử dụng agent đơn giản đến phức tạp, cũng như từ phát triển cục bộ đến triển khai trong môi trường production.",
    "tags": [],
    "title": " Blog 7",
    "uri": "/vi/3-blogstranslated/3.7-blog7/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "Mục tiêu tuần 7: Thực hành các bài lab về việc triển khai ứng dụng lên AWS\nDịch các bài blogs\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chỉnh sửa API tự động thông báo cho dự án cuối khóa 20/10/2025 20/10/2025 3 - Thực hành: lab15: Triển khai ứng dụng trên Docker với AWS 21/10/2025 21/10/2025 https://000015.awsstudygroup.com/vi/ 4 - Dịch bài blogs: Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên 22/10/2025 22/10/2025 Blog 6 5 - Dịch bài blogs: Ra Mắt Strands Agents 1.0: Đơn Giản Hóa Việc Điều Phối Đa tác tử Đã Sẵn Sàng Triển Khai 23/10/2025 23/10/2025 Blog 7 6 - Thực hành: lab58: Làm việc với Amazon System Manager - Session Manager 24/10/2025 24/10/2025 https://000058.awsstudygroup.com/vi/ Kết quả đạt được tuần 7: Thực hành bài lab tạo image và triển khai ứng dụng với docker\nThực hành lưu image của docker lên docker hub và Amazon ECR\nThực hành truy cập vào ec2 thông qua session manager để tăng cường bảo mật. Tránh việc mở port 22 để ssh hoặc bị lộ key-pair để ssh vào instance",
    "description": "Mục tiêu tuần 7: Thực hành các bài lab về việc triển khai ứng dụng lên AWS\nDịch các bài blogs\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chỉnh sửa API tự động thông báo cho dự án cuối khóa 20/10/2025 20/10/2025 3 - Thực hành: lab15: Triển khai ứng dụng trên Docker với AWS 21/10/2025 21/10/2025 https://000015.awsstudygroup.com/vi/ 4 - Dịch bài blogs: Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên 22/10/2025 22/10/2025 Blog 6 5 - Dịch bài blogs: Ra Mắt Strands Agents 1.0: Đơn Giản Hóa Việc Điều Phối Đa tác tử Đã Sẵn Sàng Triển Khai 23/10/2025 23/10/2025 Blog 7 6 - Thực hành: lab58: Làm việc với Amazon System Manager - Session Manager 24/10/2025 24/10/2025 https://000058.awsstudygroup.com/vi/ Kết quả đạt được tuần 7: Thực hành bài lab tạo image và triển khai ứng dụng với docker",
    "tags": [],
    "title": "Tuần 7",
    "uri": "/vi/1-worklog/1.7-week7/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Các bài blog đã dịch",
    "content": "Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2 Eric Allen, Mark Azadpour, Deepthi Shankar, Olivia Choudhury, và Shyamal Mehtalia | 15/07/2025 | High Performance Computing, Life Sciences, Partner solutions\nBài viết này được đóng góp bởi Eric Allen (AWS), Olivia Choudhury (AWS), Mark Azadpour (AWS), Deepthi Shankar (Illumina), và Shyamal Mehtalia (Illumina)\nViệc phân tích lượng dữ liệu genomic và multiomic ngày càng gia tăng đòi hỏi các giải pháp tính toán hiệu quả, có khả năng mở rộng và tiết kiệm chi phí. Amazon Web Services (AWS) tiếp tục hỗ trợ các workload này thông qua các dịch vụ tính toán tăng tốc FPGA như các instance Amazon EC2 F2.\nGiải pháp phân tích thứ cấp DRAGEN (Dynamic Read Analysis for GENomics) của Illumina đã khẳng định vị thế là một trong những giải pháp phân tích thứ cấp hàng đầu cho dữ liệu sequencing thế hệ mới, cung cấp các thuật toán được tối ưu hóa cao cho phân tích genomic và triển khai tăng tốc phần cứng cho các pipeline phân tích toàn diện về genomics và multiomics, bao gồm DNA germline, DNA somatic, cũng như phân tích RNA ở mức bulk và single-cell, proteomics, spatial, và nhiều hơn nữa.\nDRAGEN chạy nguyên bản trên các instance EC2 F2 và cung cấp cho khách hàng một phương pháp nhanh chóng để phân tích tập dữ liệu sinh học của họ. Việc di chuyển sang F2 được đơn giản hóa vì cùng một DRAGEN AMI được sử dụng cho cả F1 và F2, và kết quả phân tích sẽ tương đương nhau. Trong bài viết này, chúng tôi sẽ thảo luận về các đặc tính hiệu năng của DRAGEN trên các môi trường tính toán AWS khác nhau, cũng như cách triển khai phiên bản DRAGEN v4.4 mới ra mắt gần đây trên các instance Amazon EC2 F2.\nTổng quan về các instance Amazon EC2 F2 Các instance F2 là thế hệ thứ 2 của các instance EC2 được trang bị FPGA để tăng tốc phân tích dữ liệu genomic và multimedia trong môi trường cloud. Những instance này mang lại cải tiến đáng kể so với thế hệ trước — các instance F1 — với hiệu suất giá thành được cải thiện tốt hơn tới 60%. Dưới đây là các tính năng và thông số kỹ thuật chính của instance F2:\nCấu hình FPGA: Instance F2 được trang bị tối đa tám AMD Virtex UltraScale+ HBM VU47P FPGAs, mỗi FPGA tích hợp 16GB bộ nhớ băng thông cao (HBM – High-Bandwidth Memory).\nBộ xử lý: Được vận hành bởi bộ vi xử lý AMD EPYC thế hệ thứ 3 (Milan), instance F2 cung cấp tới 192 vCPU — gấp ba lần số lõi xử lý so với instance F1.\nBộ nhớ: Instance này hỗ trợ tới 2 TiB bộ nhớ hệ thống, gấp đôi dung lượng bộ nhớ của instance F1.\nLưu trữ: F2 đi kèm với tối đa 7.6 TiB bộ nhớ SSD NVMe, gấp đôi dung lượng lưu trữ của F1.\nNetworking: Tốc độ băng thông mạng lên tới 100 Gbps, cao gấp bốn lần so với băng thông mạng có sẵn trên instance F1.\nInstance Name\rFPGAs\rvCPUs\rInstance Memory\rNVMe Storage\rNetwork Bandwidth\rf1.2xlarge\r1\r8\r122\r470\rUp to 10 Gbps\rf1.4xlarge\r2\r16\r244\r940\r10 Gbps\rf2.6xlarge\r1\r24\r256\r950\r10 Gbps\rF2.12xlarge\r2\r48\r512\r1900\r25 Gbps\rf1.16xlarge\r8\r64\r976\r44x940\r25 Gbps\rF2.48xlarge\r8\r192\r2048\r7600\r100 Gbps\rBảng 1: Bảng so sánh thông số kỹ thuật về compute, memory, storage, và networking giữa các instance F1 và F2.\nPhương pháp đánh giá hiệu năng Illumina khuyến nghị sử dụng f1.4xlarge khi dùng instance F1 và f2.6xlarge khi dùng instance F2. Để đánh giá hiệu năng trên các instance này, DRAGEN đã được cấu hình và chạy trên AWS theo hướng dẫn người dùng Illumina DRAGEN, và các liên kết tới genome reference file có thể tìm thấy trên trang web Illumina DRAGEN Product Files.\nPhân tích Whole Genome Sequencing (WGS) với độ phủ khoảng 35x sử dụng một mẫu có sẵn công khai. Mẫu HG002 từ dự án NIST Genome in a Bottle đã được sử dụng. Mẫu này được phân tích bằng DRAGEN v4.4 Germline pipeline theo hai cách khác nhau. Phân tích “cơ bản” chỉ bao gồm alignment cơ bản và small variant calling, nhằm tạo điều kiện so sánh với các pipeline tin sinh học phổ biến cho mẫu germline như BWA/GATK. Phân tích “đầy đủ” sử dụng tất cả các variant caller, bao gồm cả copy number và structural variants, cùng các tùy chọn bổ sung như gọi pharmacogenetic star allele và gọi HLA (Human Leukocyte Antigen), để tạo ra một bộ genome được phân tích đầy đủ. Trong cả hai trường hợp, tham chiếu đồ thị multigenome hg38 của DRAGEN được sử dụng cho phân tích WGS. Các file dữ liệu fastq của mẫu có thể truy cập trên Amazon S3 qua các liên kết: fastq R1, fastq R2.\nPhân tích Tumor-Normal sử dụng một cặp mẫu đã được khảo sát trong một ấn phẩm về phân tích ung thư của DRAGEN trước đây. Hai mẫu này có độ phủ khoảng 110x (tumor) và 40x (normal). Các mẫu được phân tích bằng DRAGEN v4.4 Somatic pipeline, bao gồm alignment, small variant calling, cũng như phân tích CNV và SV. Phân tích Tumor-Normal sử dụng hg38 linear genome reference của DRAGEN. Các file dữ liệu fastq của mẫu có thể truy cập trên Amazon S3 qua các liên kết: Tumor fastq R1, Tumor fastq R2, Normal fastq R1, Normal fastq R2.\nSo sánh hiệu năng về tốc độ và chi phí: Phân tích WGS Phân tích WGS sử dụng DRAGEN v4.4 cho thấy lợi thế đáng kể về hiệu suất chi phí trên các instance Amazon EC2 F2 so với F1, đồng thời vẫn cho ra kết quả phân tích tương đương giữa hai thế hệ instance¹:\nPhân tích WGS cơ bản, bao gồm alignment và small variant calling. DRAGEN v4.4 chạy trên f2.6xlarge đạt tốc độ nhanh hơn 1,5 lần và chỉ tốn 40% chi phí compute EC2 so với f1.4xlarge.\nPhân tích WGS đầy đủ, bao gồm alignment, small variant calling, calling of CNVs, SVs, repeat expansions, và variant annotation. Phân tích DRAGEN trên f2.6xlarge đạt tốc độ nhanh gấp 2 lần và chỉ tốn 30% chi phí compute EC2 so với f1.4xlarge.\nHình 1: Instance f2.6xlarge nhanh hơn 1.5 lần trong Phân tích WGS cơ bản và nhanh hơn 2.1 lần trong Phân tích WGS đầy đủ so với f1.4xlarge.\nHình 2: Chi phí compute EC2 trên f2.6xlarge chỉ bằng 40% chi phí trên f1.4xlarge cho Phân tích WGS cơ bản và bằng 30% chi phí trên f1.4xlarge cho Phân tích WGS đầy đủ.\nSo sánh hiệu năng về tốc độ và chi phí: Phân tích Tumor-Normal Giống như kết quả WGS, trong phân tích Tumor-Normal, DRAGEN v4.4 cũng cho thấy lợi thế đáng kể về hiệu suất chi phí trên các instance Amazon EC2 F2 so với F1, đồng thời vẫn tạo ra kết quả phân tích tương đương giữa hai thế hệ instance¹:\nPhân tích Tumor-Normal, bao gồm alignment, small variant calling và calling CNVs/SVs. Phân tích bằng DRAGEN trên f2.6xlarge đạt tốc độ nhanh hơn 1.7 lần và chỉ tốn 35% chi phí compute EC2 so với f1.4xlarge. Hình 3: Instance f2.6xlarge nhanh hơn 1.7 lần so với f1.4xlarge trong Phân tích Tumor-Normal.\nHình 4: Chi phí compute EC2 trên f2.6xlarge chỉ bằng 35% chi phí trên f1.4xlarge cho Phân tích Tumor-Normal WGS.\nCác lợi ích khác Các pipeline phân tích genomic truyền thống sử dụng BWA-MEM và GATK chạy trên CPU từng là tiêu chuẩn công nghiệp trong quá khứ, nhưng DRAGEN đã ngày càng được ưa chuộng nhờ những ưu thế vượt trội về tốc độ và độ chính xác. Nhiều công bố đã được bình duyệt đã so sánh tốc độ và độ chính xác của DRAGEN với các pipeline dựa trên BWA/GATK chạy trên CPU. Ví dụ, Ziegler et al. (2022) đã phát hiện ra rằng phân tích DRAGEN trên phần cứng FPGA nhanh hơn gấp hơn 8 lần và chính xác hơn so với các pipeline dựa trên BWA/GATK chạy trên CPU, trong khi Sedlazek et al. (2024) cũng ghi nhận DRAGEN cho hiệu suất và độ chính xác cao hơn so với các pipeline dựa trên BWA/GATK.\nViệc sử dụng DRAGEN trên các instance F, được tăng tốc bởi FPGA, còn mang lại lợi thế về tiêu thụ điện năng so với các giải pháp truyền thống dựa trên CPU và GPU. FPGA vốn dĩ tiết kiệm năng lượng hơn, tiêu thụ ít điện năng hơn nhưng vẫn đạt hiệu năng tính toán tương đương cho các workload này. Điều này đặc biệt quan trọng trong các tác vụ phân tích dữ liệu genomic, nơi khối lượng dữ liệu và thời gian xử lý có thể rất lớn.\nChẳng hạn, FPGA đạt được hiệu suất trên mỗi watt cao hơn so với CPU và GPU trong các tác vụ WGS của DRAGEN. Các bộ tăng tốc dựa trên FPGA có thể cung cấp thông lượng vượt trội với mức tiêu thụ điện năng thấp hơn. Điều này là nhờ khả năng tùy chỉnh linh hoạt của FPGA, cho phép cấu hình tối ưu hóa nhằm nâng cao hiệu quả năng lượng. Ngược lại, CPU và GPU, dù mạnh mẽ, thường tiêu tốn nhiều năng lượng hơn để thực hiện cùng một tác vụ, dẫn đến chi phí vận hành cao hơn và tác động môi trường lớn hơn.\nViệc tiêu thụ điện năng thấp hơn của các FPGA dẫn đến giảm các yêu cầu về làm mát, đây có thể là một yếu tố chi phí đáng kể trong các môi trường điện toán quy mô lớn. Ngoài ra, hiệu quả năng lượng của FPGA khiến chúng trở thành lựa chọn hấp dẫn cho các ứng dụng điện toán hiệu năng cao, nơi khả năng mở rộng và hiệu quả chi phí đóng vai trò then chốt.\nTóm lại, việc triển khai DRAGEN trên các instance thuộc họ ‘F’ của Amazon EC2 mang lại một giải pháp tiết kiệm năng lượng hơn cho phân tích dữ liệu genomic so với các phương pháp truyền thống dựa trên CPU hoặc GPU, đồng thời mang lại cả lợi ích về chi phí lẫn lợi ích môi trường.\nKhả năng triển khai và các tùy chọn triển khai trên cloud của instance F2 Các instance Amazon EC2 F2 hiện đã có sẵn tại nhiều Region của AWS, bao gồm US East (N. Virginia), US West (Oregon), Europe (London) và Asia Pacific (Sydney), với kế hoạch mở rộng thêm sang nhiều Region khác trong tương lai. F2 cung cấp nhiều kích cỡ khác nhau như f2.6xlarge, f2.12xlarge và f2.48xlarge, nhằm đáp ứng đa dạng nhu cầu workload.\nKhi cấu hình lưu trữ và compute để chạy các workload DRAGEN trên các instance F của AWS, bạn cần lựa chọn các tùy chọn phù hợp để cân bằng giữa hiệu năng và chi phí. Hãy cân nhắc các tùy chọn lưu trữ như là Amazon EBS gp3 volumes được cấu hình theo RAID, Amazon FSx for Lustre cho thông lượng cao hơn và Amazon Elastic File System (EFS) cho lưu trữ liên tục. Ngoài ra, việc truyền trực tuyến các tệp BAM và dữ liệu tham chiếu từ Amazon Simple Storage Service (Amazon S3) hoặc sử dụng Mountpoint for Amazon S3 để mount bucket S3 vào hệ thống file cục bộ giúp truy cập dữ liệu một cách tiết kiệm chi phí và dễ dàng. Bằng cách lựa chọn và cấu hình cẩn thận các giải pháp lưu trữ này, bạn có thể đảm bảo hiệu năng tối ưu và hiệu quả chi phí cho các workload HPC của mình. Bên cạnh đó, bạn cũng nên cân nhắc sử dụng Illumina Connected Analytics (ICA) hoặc AWS Batch để quản lý workflow. Illumina cung cấp hướng dẫn chi tiết về cách triển khai DRAGEN trên AWS trong tài liệu hướng dẫn người dùng DRAGEN trực tuyến của họ.\nKết luận Tóm lại, các instance Amazon EC2 F2 đánh dấu một bước tiến đáng kể trong lĩnh vực điện toán đám mây được cung cấp bởi FPGA, mang lại hiệu năng, bộ nhớ, dung lượng lưu trữ và khả năng kết nối mạng vượt trội so với thế hệ trước. Sự kết hợp giữa các pipeline toàn diện của DRAGEN và sức mạnh tính toán được nâng cấp của Amazon EC2 F2 cho phép xử lý nhanh hơn, hiệu quả hơn đối với các bộ dữ liệu phức tạp – từ whole genome sequencing đến phân tích single-cell RNA.\nHãy bắt đầu chuyển đổi sang F2 ngay hôm nay. Vui lòng liên hệ với đội ngũ tài khoản AWS của bạn hoặc Illumina để được hỗ trợ trong quá trình chuyển đổi sang Amazon EC2 F2 instances.\nĐể biết thêm thông tin về DRAGEN trên AWS, hãy tìm kiếm DRAGEN Complete Suite trên AWS Marketplace, xem blog DRAGEN v4.4, hoặc truy cập trang chủ Illumina Informatics Solutions.\nTài liệu tham khảo Scheffler, K. et al. “Somatic small-variant calling methods in Illumina DRAGEN™ Secondary Analysis.” BioRxiv (2023). https://www.biorxiv.org/content/10.1101/2023.03.23.534011v2\nSedlazeck, F. J. et al. “Comprehensive genome analysis and variant detection at scale using DRAGEN.” Nature Biotechnology (2024). https://www.nature.com/articles/s41587-024-02382-1\nZiegler, A. et al. “Comparison of calling pipelines for whole genome sequencing: an empirical study demonstrating the importance of mapping and alignment.” Scientific Reports (2022). https://pubmed.ncbi.nlm.nih.gov/36513709/\nChú thích Sự tương đương giữa F1 và F2 hard-filtered.vcf cùng các tệp kết quả khác dựa trên kết quả phân tích sử dụng DRAGEN 4.4.4 theo hướng dẫn sử dụng DRAGEN của Illumina. Lệnh vim diff cho thấy sự khác biệt duy nhất giữa hai tệp VCF là một mục hiển thị thời gian thực hiện phân tích. Khách hàng có thể tự thực hiện các phân tích tương tự để xác minh hoặc liên hệ với Illumina để biết thêm thông tin.",
    "description": "Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2 Eric Allen, Mark Azadpour, Deepthi Shankar, Olivia Choudhury, và Shyamal Mehtalia | 15/07/2025 | High Performance Computing, Life Sciences, Partner solutions\nBài viết này được đóng góp bởi Eric Allen (AWS), Olivia Choudhury (AWS), Mark Azadpour (AWS), Deepthi Shankar (Illumina), và Shyamal Mehtalia (Illumina)",
    "tags": [],
    "title": " Blog 8",
    "uri": "/vi/3-blogstranslated/3.8-blog8/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập \u003e Worklog",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Tuần 8",
    "uri": "/vi/1-worklog/1.8-week8/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Thông tin sinh viên: Họ và tên: Lê Trung Kiên\nSố điện thoại: 0931261009\nEmail: trungkien1862@gmail.com\nTrường: Đại học Sài Gòn\nNgành: Công nghệ thông tin\nLớp: DCT1213\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 11/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến",
    "description": "Thông tin sinh viên: Họ và tên: Lê Trung Kiên\nSố điện thoại: 0931261009\nEmail: trungkien1862@gmail.com\nTrường: Đại học Sài Gòn\nNgành: Công nghệ thông tin\nLớp: DCT1213\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 11/11/2025",
    "tags": [],
    "title": "Báo cáo thực tập",
    "uri": "/vi/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Thể loại",
    "uri": "/vi/categories/index.html"
  },
  {
    "breadcrumb": "Báo cáo thực tập",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Thẻ",
    "uri": "/vi/tags/index.html"
  }
]
